---
layout: post
title:  "머신러닝 | 1-3. 마켓과 머신러닝"
date:   2024-07-29 13:11
categories: CUDA MachineLearning 혼공머신 1.나의첫머신러닝
---


### 가장 간단한 머신러닝 알고리즘 중 하나인 k-최근접 이웃을 사용하여 2개의 종류를 분류하는 머신러닝 모델을 훈련

## 생선 분류 문제
30cm보다 크면 도미!
근데 큰 생선이라고 다 도미는 아니다. 
또 도미의 크기가 모두 같을 리도 없다. 어떻게 바뀌지 않을 기준을 정할까?   

프로그램은 '누군가 정해준 기준대로' 일을 한다. 반대로 **머신러닝**은 '스스로 기준을 찾아서' 일을 한다. 누구도 알려주지 않은 기준을 찾아서 일을 한다. 머신러닝이 '30cm에서 40cm 길이의 생선은 도미이다' 라는 기준을 찾는 것이다. 



### 도미 데이터 준비하기

> 이진분류   
> **분류**: 머신러닝에서 여러개의 종류 또는 **클래스**(파이썬에서의 클래스와 다르다) 중 하나를 구별해 내는 문제    
> **이진분류**: 2개의 클래스 중 하나를 고르는 문제

```
bream_length=[32.3, 34.5, ---복붙한 내용]
bream_weight=[253.3, 535.2, ---]
```
첫번째 도미의 길이는 32.3이고 무게는 253.3    
각 도미의 특징을 길이와 무게로 표현한 것이다.
이런 특징을 **특성** 이라고 부른다. 특성은 데이터의 특징!

![alt 도미](/assets/img/1.3도미.png)

두 특성을 숫자보다 그래프로 표현하면 데이터를 잘 이해할 수 있고 앞으로 할 작업에 대한 단서를 얻을 수 있다   
길이를 x축, 무게를 y축으로 하고 각 도미를 그래프에 점으로 표현한다. 이런 그래프를 산점도라고 한다    
**산점도** x,y축으로 이뤄진 좌표계에 두 변수 (x,y)의 관계를 표현하는 방법

**matplotlib** 파이썬에서 과학계산용 그래프를 그리는 대표적인 패키지    
**import** 따로 만들어둔 파이썬 패키지(함수 묶음)을 사용하기 위해 불러오는 명령

matplotlib 패키지를 임포트하고 산점도를 그리는 scatter()함수 사용   

> 패키지를 임포트 할때 as키워드로 패키지 이름을 줄여서 쓰는 것을 좋아한다( ex.plt )   

```
import matplotlib.pyplot as plt #matplotlib의 pylot 함수를 plt로 줄여서 사용

plt.scatter(bream_length, bream_weight)
plt.xlabel('length') #x축은 길이, xlabel(): x축 이름
plt.ylabel('weight') #y축은 무게, ylabel(): y축 이름
plt.show() #show(): 준비된 그래프를 화면에 출력

```
![alt 도미그래프](/assets/img/1.3도미그래프.png)

2개의 특성을 사용해 그린 그래프로 2차원 그래프이다

산점도 그래프가 일직선에 가까운 형태로 나타나면 **선형적**이라고 한다

### 방어 데이터 준비하기
```
smelt_length=[9.3, 7.5, ---복붙한 내용]
smelt_weight=[3.3, 5.2, ---]
```

```
plt.scatter(bream_length, bream_weight)
plt.scatter(smelt_length, smelt_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
![alt 도미방어](/assets/img/1.3도미방어그래프.png)

주황색이 빙어이다. 빙어는 도미에 비해 길이도 무게도 매우 작다. 빙어의 산점도도 선형적이지만 무게가 길이에 영향을 덜 받는다고 볼 수 있다. 

## 첫 번째 머신러닝 프로그래밍
**k-최근점 이웃** 알고리즘을 사용해 도미와 빙어 데이터를 구분해보기

```
length=bream_length+smelt_length
weight=bream_weight+smelt_weight
```

**사이킷런**: 머신러닝 패키지, **2차원 리스트**(리스트의 리스트) 필요    
[[길이, 무게],[길이, 무게]]로 만드는 가장 쉬운 방법은 파이썬의 zip()함수와 리스트 내포 구문을 사용하는 것이다. <br>
zip(): 나열된 리스트 각각에서 하나씩 원소를 꺼내 반환
```
fish_data=[[l,w] for l, w in zip(length, weight)]
```

사이킷런 패키지에서 k-최근접 이웃 알고리즘을 구현한 클래스인 KNeighborsClassifier를 임포트 한다

```
from sklearn.neighbors import KNeighborsClassifier
```

임포트한 KNeighborsClassifier 클래스의 객체를 만들고 이 객체에 fish_data와 fish_target을 전달하여 도미를 찾기 위한 기준을 학습시킨다. 이러한 과정을 **훈련**이라고 한다<br>
```
kn.fit(fish_data, fish_target)
```
fit()메서드는 주어진 데이터로 알고리즘을 훈련시킨다<br>
```
kn.score(fish_data,fish_target)
```
사이킷런에서 모델을 평가하는 메서드는 score()메서드이다. 이 메서드는 0에서 1사이의 값을 반환한다. 1은 모든 데이터를 맞춘 것이다. 이 숫자의 값을 **정확도**라고 한다

>머신러닝 알고리즘을 구현한 프로그램을 모델이라고 부른다. 프로그램이 아니더라도 알고리즘을 구체화하여 표현한 것을 모델이라고 한다

### k-최근접 이웃 알고리즘
어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 한다

![alt 도미다!](/assets/img/1.3도미다!.png)

삼각형 주위에 도미 데이터가 많으므로 삼각형을 도미라고 판단한다

predict()메서드는 새로운 데이터의 정답을 예측ㅎ나다

새로운 데이터에 대해 예측할 때는 가장 가까운 직선거리에 어떤 데이터가 있는지를 살피면 된다<br>
단점: k-최근접 이웃 알고리즘의 이런 특성 때문에 데이터가 아주 많은 경우 사용하기 어렵다. 데이터가 크기 때문에 메모리가 많이 필요하고 직선거리를 계산하는 데도 많은 시간이 필요하다

가까운 데이터 몇개를 참고하는가? 이를 정할 수 있따. KNeighborsClassifier 클래스 기본 값은 5이다. 이는 n_neighbors매개 변수로 바꿀 수 있다

```
kn49=KNeoghborsClassifier(n_neighbors=49)
```
가장 가까운 데이터 49개를 사용하는 k-최근접 이웃 모델에 fish_data를 적용하면 fish_data에 있는 모든 생선을 사용하여 예측하게 된다. 

---

## 정리

### 키워드
**특성** 은 데이터를 표현하는 성질이다. 생선이 대상일때 길이와 무게를 특성으로 나타낼 수 있다.

머신러닝 알고리즘이 데이터에서 규칙을 찾는 것을 **훈련**이라고 한다. 사이킷런에서 fit()을 사용한다

**k-최근접 이웃 알고리즘**은 가장 간단한 머신러닝 알고리즘 중 하나이다. 어떤 규칙을 찾기보다는 전체 데이터를 메모리에 가지고 있는 것이다.

머신러닝 프로그램에서 알고리즘이 구현된 객체를 **모델**이라고 한다. 알고리즘 자체를 모델이라고 부르기도 한다

**정확도**는 정확한 답을 몇 개 맞혔는지를 백분율로 나타낸 값이다. 사이킷런에서는 0에서 1사이의 값으로 출력된다<br>
정확도=(정확히 맞힌 개수)/(전체 데이터 개수)

### 핵심 패키지와 함수
#### matplotlib
**scatter()** 산점도를 그리는 맷플롯립 함수이다. 2개의 매개변수로 x축 값과 y축 값을 전달한다. 이 값은 파이썬 리스트 또는 넘파이 배열이다<br>
c 매개 변수로 색깔을 지정한다<br>
marker 매개 변수로 마커 스타일을 지정한다

#### scikit-learn
**KNeighborsClassifier()**는 k-최근접 이웃 분류 모델을 만드는 사이킷런 클래스이다. n_neighbors 매개변수로 이웃의 개수를 지정한다. 기본 값은 5이다. <br>
p매개변수로 거리를 재는 방법을 지정한다.<br>
n_jobs 매개변수로 사용할 CPU 코어를 지정할 


---
참고: 혼자 공부하는 머신러닝+딥러닝