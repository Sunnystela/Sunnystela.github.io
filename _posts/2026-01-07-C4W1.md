---
layout: post
title: "[DeepLearning.AI] Course4.W1 Deep Learning Specialization"
date: 2026-01-06 12:50
categories: MyStudy DeepLearning.AI
tags: DeepLearning.AI DeepLearning
math: true
---

[Convolutional Neural Networks (Course 4 of the Deep Learning Specialization)](https://www.youtube.com/watch?v=ArPaAX_PhIs&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF)


## C4W1L01 Computer Vision

### **1. 컴퓨터 비전의 발전과 딥러닝의 역할**
**응용 분야:**  
딥러닝을 통한 컴퓨터 비전 기술은 자율주행 자동차(보행자 및 차량 회피) 얼굴 인식(잠금 해제) 사진 큐레이션 그리고 예술 창작의 새로운 지평을 여는 데 사용되고 있습니다.

**학습의 중요성:**  
컴퓨터 비전을 배워야 하는 이유는 기술의 빠른 발전으로 이전에는 불가능했던 새로운 애플리케이션을 만들 수 있기 때문이다. 또한 컴퓨터 비전 연구 커뮤니티의 창의적인 신경망 구조와 알고리즘은 음성 인식과 같은 다른 분야에도 많은 영감을 주고 있습니다.

### **2. 주요 컴퓨터 비전 문제 유형**
**이미지 분류 (Image Classification):**  
입력된 이미지가 고양이인지 아닌지를 식별하는 것과 같은 작업이다.

**물체 감지 (Object Detection):**  
자율주행차의 예시처럼 단순히 물체의 유무뿐만 아니라 물체의 위치를 파악하여 박스로 표시하고 식별하는 기술이다.

**신경망 스타일 변형 (Neural Style Transfer):**  
원본 사진(컨텐츠)에 피카소 그림과 같은 특정 화풍(스타일)을 입혀 새로운 예술적 이미지를 재구성하는 기술이다.

### **3. 입력 데이터의 크기와 기존 신경망의 한계**
**입력 차원의 증가:**  
64x64 픽셀의 작은 컬러 이미지는 입력 특성(feature)이 12288개 수준이지만 1000x1000 픽셀의 고해상도 이미지는 입력 차원이 3백만(3000000) 개로 급증한다.

**파라미터 폭증 문제:**  
만약 1000x1000 이미지를 표준 완전 연결 신경망(Standard Fully Connected Network)에 넣고 첫 번째 은닉층 유닛을 1000개로 설정한다면 가중치 행렬(W1)의 변수 개수는 30억 개가 됩니다.

**결과:**  
이렇게 변수가 많으면 과적합(Overfitting)을 방지할 충분한 데이터를 얻기 어렵고 계산 및 메모리 요구량이 너무 커져서 학습이 불가능해집니다.

### **4. 해결책: 합성곱 연산 (Convolution)**
큰 이미지를 효율적으로 처리하기 위해서는 **합성곱(Convolution)** 연산을 구현해야 한다.
합성곱은 합성곱 신경망(CNN)의 기본 빌딩 블록이 되며 다음 강의에서 윤곽선 검출(Edge Detection) 예시를 통해 구체적인 원리를 다룰 예정이다.

## C4W1L02 Edge Detection Examples

이 강의는 합성곱 신경망(CNN)의 핵심 연산인 **합성곱(Convolution)**이 이미지에서 어떻게 수직 모서리(Vertical Edge)를 감지하는지 설명하고 있습니다.

### 1. 합성곱 신경망과 모서리 감지의 개요
합성곱 연산은 CNN의 가장 기본이 되는 구성 요소이다.
신경망의 하위 층(초기 층)은 이미지의 모서리를 감지하고 이후 층들은 부분적인 물체를 더 깊은 층들은 전체 물체(예: 사람의 얼굴)를 인식하는 구조를 가집니다.
이미지 인식의 첫 단계는 이미지 내의 수직선(예: 난간 보행자 윤곽선)이나 수평선 같은 모서리를 찾아내는 것이다.

### 2. 수직 모서리 감지를 위한 설정 (이미지와 필터)
예시로 6x6 크기의 그레이스케일(흑백) 이미지를 사용한다.
수직 모서리를 감지하기 위해 **3x3 크기의 필터(Filter)**를 사용한다. (어떤 논문에서는 이를 '커널'이라고도 부릅니다).
이 영상에서 사용된 수직 모서리 감지 필터의 값은 다음과 같습니다:
    $$\begin{bmatrix} 1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1 \end{bmatrix}$$

### 3. 합성곱 연산 과정 (Convolution Operation)
6x6 이미지와 3x3 필터를 합성곱하면 4x4 크기의 결과 행렬(이미지)을 얻게 됩니다.

**계산 방법:**
1.  필터를 이미지의 왼쪽 상단 3x3 영역에 겹쳐 놓습니다.
2.  겹치는 위치의 요소끼리 곱한 뒤 그 9개의 값을 모두 더한다. (예: 첫 번째 연산 결과는 -5).
3.  필터를 오른쪽으로 한 칸 이동시켜 같은 과정을 반복한다. (두 번째 결과는 -4 그 다음은 0 8 순서).
4.  한 줄이 끝나면 필터를 한 칸 아래로 내려서 다시 반복한다.

### 4. 프로그래밍 구현 시 참고사항
수학적으로는 합성곱을 별표($*$)로 표시하지만 파이썬 등 프로그래밍 언어에서 별표는 일반적인 곱셈을 의미할 수 있어 주의해야 한다.
실제 코딩(텐서플로 케라스 등)에서는 `tf.nn.conv2d`나 `Conv2d`와 같은 전용 함수를 사용하여 합성곱을 구현한다.

### 5. 수직 모서리 감지의 원리 (직관적 이해)
**단순화된 예시:**  
왼쪽 절반은 밝은 픽셀(값 10) 오른쪽 절반은 어두운 픽셀(값 0)인 이미지가 있다고 가정해 봅시다. 이 이미지는 가운데에 뚜렷한 수직 경계선이 있습니다.
이 이미지에 앞서 소개한 3x3 필터(왼쪽은 1 가운데는 0 오른쪽은 -1)를 적용하면 다음과 같은 결과가 나옵니다.  
    **경계선 부분:**  
    밝은 영역(10)과 어두운 영역(0)에 걸쳐 있는 필터는 `10 + 10 + 10 - 0 - 0 - 0`과 같은 연산을 통해 **30**이라는 높은 값을 출력한다.  
    **평평한 부분:**  
    색 변화가 없는 영역(모두 0이거나 모두 10인 곳)은 연산 결과가 **0**이 됩니다.
결과적으로 출력된 행렬을 이미지로 보면 가운데 부분만 밝게 빛나는(값 30) 영역이 나타나며 이것이 바로 원본 이미지의 **수직 경계선**을 의미한다.

필터가 이미지상의 밝기 변화(밝음 $\rightarrow$ 어두움)를 감지하여 해당 위치를 높은 숫자로 출력함으로써 컴퓨터가 '여기에 수직 모서리가 있다'라고 인식하게 만드는 원리이다.



## C4W1L03 More Edge Detection

### **1. 윤곽선(Edge)의 방향성: 양과 음의 차이**
지난 강의의 세로 윤곽선 검출에 이어 밝기 전환의 방향에 따른 결과값의 차이를 설명한다.  
**밝음 → 어두움:**  
필터를 적용했을 때 양수(예: 30)가 나옵니다.  
**어두움 → 밝음:**  
이미지가 반전되면 결과값도 부호가 바뀌어 음수(예: -30)가 나옵니다. 이를 통해 단순히 윤곽선이 있다는 사실뿐만 아니라 밝기 변화의 순서(방향)까지 알 수 있습니다.
만약 변화의 방향이 중요하지 않다면 결과에 절댓값을 취하여 처리할 수도 있습니다.

### **2. 가로(수평) 윤곽선 검출**
세로 윤곽선 필터를 90도 회전시키면 가로 윤곽선을 검출하는 필터가 됩니다.
3x3 필터를 기준으로 위쪽이 밝고 아래쪽이 어두우면 양의 윤곽선 반대의 경우 음의 윤곽선으로 인식한다.
복잡한 이미지(예: 체크무늬)에 적용할 경우 필터가 양의 윤곽선과 음의 윤곽선을 모두 포함하는 영역을 지나갈 때 -10과 같은 중간값이 나올 수 있지만 이미지가 매우 클 경우(예: 1000x1000) 이러한 중간값은 크게 눈에 띄지 않습니다.

### **3. 역사적으로 사용된 다양한 필터들 (Sobel Scharr)**
과거 컴퓨터 비전 분야에서는 어떤 숫자의 조합이 최적의 필터인지에 대한 논쟁이 있었습니다.

**소벨(Sobel) 필터:**  
(1 2 1) 등의 숫자를 사용하여 중간 픽셀에 더 중점을 두어 견고함을 높인 필터이다.

**샤르(Scharr) 필터:**  
(3 10 3) 등의 숫자를 사용하는 필터로 소벨과는 또 다른 속성을 가집니다.

### **4. 딥러닝을 통한 필터 학습 (핵심)**
딥러닝의 발전으로 인해 복잡한 이미지에서 윤곽선을 검출할 때 더 이상 사람이 직접 필터의 숫자(9개의 값)를 고민하여 고를 필요가 없어졌습니다.

**매개변수 학습:**  
필터의 숫자들을 변수(parameter)로 설정하고 역전파(Backpropagation)를 통해 데이터로부터 스스로 학습하게 한다.
이렇게 학습된 신경망은 소벨이나 샤르 필터보다 더 좋은 성능을 낼 수 있으며 단순히 가로/세로뿐만 아니라 43도 70도 등 다양한 각도의 윤곽선까지 검출할 수 있는 강력한 방식이다.



**요약하자면:**
기존에는 사람이 직접 설계한(Hand-coded) 필터로 가로/세로 윤곽선의 방향성을 탐지했으나 딥러닝에서는 **필터의 값 자체를 학습 가능한 변수로 두어** 데이터에 가장 적합한 윤곽선 검출기를 스스로 만들어낸다는 것이 이 강의의 핵심이다.

## C4W1L04 Padding

### **1. 기존 합성곱 연산의 두 가지 단점**
강의 초반부에서는 패딩(Padding)이 없는 기존 합성곱 연산($n \times n$ 이미지와 $f \times f$ 필터)의 문제점을 지적한다.

**이미지 축소:**  
연산을 거칠 때마다 이미지 크기가 $(n - f + 1) \times (n - f + 1)$로 줄어듭니다. 예를 들어 6x6 이미지를 3x3 필터로 연산하면 4x4가 됩니다. 신경망이 깊어질수록 이미지가 지나치게 작아져 더 이상 연산할 수 없게 되거나 정보가 소실됩니다.

**가장자리 정보 손실:**  
이미지 중앙의 픽셀은 필터가 지나가면서 여러 번 연산에 포함되지만 가장자리나 모서리의 픽셀은 한 번만 사용되거나 훨씬 적게 사용됩니다. 결과적으로 가장자리의 정보가 무시되는 경향이 발생한다.

### **2. 해결책: 패딩 (Padding)**
위의 두 문제를 해결하기 위해 합성곱 연산 전에 이미지 가장자리에 픽셀(주로 0)을 덧대는 '패딩' 기법을 사용한다.

**원리:**  
이미지 주변에 $p$만큼의 픽셀을 덧대면 입력 이미지는 $(n + 2p) \times (n + 2p)$가 됩니다.

**결과:**  
패딩 후 합성곱을 수행하면 출력 크기는 $(n + 2p - f + 1)$이 됩니다. 이를 통해 출력 이미지의 크기를 입력 이미지와 동일하게 유지할 수 있으며 가장자리 픽셀도 필터의 중앙 부분에서 연산될 기회를 얻어 정보 손실을 줄일 수 있습니다.

### **3. 패딩의 종류: 유효(Valid) 합성곱 vs 동일(Same) 합성곱**

**유효 합성곱 (Valid Convolutions):**  
패딩을 적용하지 않는 경우이다 ($p=0$). 출력 이미지는 입력보다 작아집니다.

**동일 합성곱 (Same Convolutions):**  
출력 이미지의 크기가 입력 이미지와 같아지도록 패딩을 설정하는 경우이다.
    입력($n$)과 출력($n + 2p - f + 1$)이 같아지려면 패딩의 크기는 $p = (f - 1) / 2$ 공식을 따릅니다.

### **4. 필터 크기(f)에 대한 관습**
컴퓨터 비전 분야에서는 필터의 크기 $f$를 주로 **홀수(Odd number)**로 사용한다 (예: 3x3 5x5).

**이유 1 (대칭성):**  
$f$가 짝수라면 동일 합성곱(Same convolution)을 위해 필요한 패딩 $p$가 정수가 되지 않아 비대칭 패딩(왼쪽과 오른쪽을 다르게 패딩)을 해야 한다. 홀수일 때만 상하좌우 대칭으로 패딩을 적용할 수 있습니다.

**이유 2 (중심 픽셀):**  
홀수 크기의 필터는 명확한 하나의 중심 픽셀(center pixel)을 가집니다. 이는 컴퓨터 비전에서 위치 정보를 다룰 때 편리한다.

이 강의는 합성곱 신경망에서 **이미지가 지나치게 작아지는 것을 방지**하고 **가장자리 정보를 보존**하기 위해 **패딩(Padding)**을 사용하며 주로 **홀수 크기의 필터**를 사용하여 입출력 크기를 동일하게 맞추는 **'Same Convolution'** 기법을 설명하고 있습니다.

## C4W1L05 Strided Convolutions


### **1. 스트라이드(Stride) 합성곱의 개념과 예시**
**기본 원리:**  
기존의 합성곱이 필터를 한 칸씩 이동하며 연산했다면 스트라이드 합성곱은 지정된 간격($s$)만큼 건너뛰며 이동한다.

**연산 예시:**  
$7 \times 7$ 이미지를 $3 \times 3$ 필터로 합성곱 할 때 스트라이드($s$)를 2로 설정한다고 가정해 봅니다.
    이 경우 필터(파란 박스)가 가로와 세로 모두 한 번에 두 칸씩 이동한다.
    그 결과 일반적인 합성곱보다 출력 크기가 줄어들어 $3 \times 3$ 크기의 결과물을 얻게 됩니다.

### **2. 출력 크기(Output Size) 계산 공식**
**공식:**  
$n \times n$ 이미지 $f \times f$ 필터 패딩 $p$ 스트라이드 $s$가 주어졌을 때 출력 크기는 다음과 같습니다.
    $$ \left\lfloor \frac{n + 2p - f}{s} + 1 \right\rfloor $$
    여기서 $\lfloor \cdot \rfloor$ 기호는 내림(floor) 연산을 의미한다.

**내림 연산의 의미:**  
계산 결과가 정수가 아닐 경우(분수 꼴일 경우) 내림을 한다. 이는 필터가 패딩을 포함한 이미지 영역 안에 완전히 들어올 때만 연산을 수행하고 필터의 일부가 밖으로 빠져나가는 경우에는 계산하지 않는다는 것을 의미한다.

### **3. 수학적 합성곱 vs 딥러닝의 합성곱 (교차상관)**
**수학적 정의와의 차이:**  
일반적인 수학 교과서나 신호 처리 분야에서 정의하는 '합성곱(Convolution)'은 연산 전에 필터를 가로축과 세로축으로 뒤집는(mirroring) 과정이 포함됩니다.
    예를 들어 필터 $\begin{bmatrix} 3 & 4 \\ 1 & 0 \end{bmatrix}$을 $\begin{bmatrix} 0 & 1 \\ 4 & 3 \end{bmatrix}$ 처럼 역순으로 뒤집은 뒤 연산한다.

**딥러닝의 관습:**  
딥러닝에서는 이 '뒤집는 과정'을 생략하고 필터 그대로 연산한다. 수학적으로 엄밀히 따지면 이는 **'교차상관(Cross-correlation)'**이라고 부르는 것이 맞습니다.

**이유:**  
필터를 뒤집는 것은 수학적 결합법칙 등의 성질을 만족시키기 위함인데 딥러닝 신경망에서는 이러한 성질이 큰 의미가 없으며 뒤집는 과정을 생략하는 것이 구현을 단순화하기 때문이다.

**결론:**  
딥러닝 분야에서는 사실상 '교차상관' 연산을 수행하지만 관습적으로 이를 **'합성곱(Convolution)'**이라고 부릅니다.




## C4W1L06 Convolutions Over Volumes
이 강의는 2D 이미지를 넘어 3D 입체형(Volume) 데이터(예: RGB 이미지)에 대해 합성곱 연산을 어떻게 수행하는지 설명하고 있습니다.

### 1. 3D 입체형(Volume)에서의 합성곱 개요
기존의 2D 이미지가 아닌 높이 너비 그리고 색상 채널(Red Green Blue)을 가진 3D 이미지를 다루는 방법이다.

**입력 데이터의 차원:**  
흑백 이미지가 아닌 RGB 이미지는 $6 \times 6 \times 3$의 크기를 가집니다. 여기서 3은 색상 채널의 수를 의미한다.

**필터의 차원:**  
3D 이미지를 처리하기 위한 필터 역시 3D 형태여야 한다. 예를 들어 $3 \times 3 \times 3$ 크기를 가집니다.

**중요 규칙:**  
입력 이미지의 채널 수와 필터의 채널 수는 **반드시 일치**해야 한다. (예: 이미지가 3채널이면 필터도 3채널).

### 2. 합성곱 연산 과정
필터가 이미지 위를 이동하며 연산을 수행하는 구체적인 과정이다.

**연산 방법:**  
$3 \times 3 \times 3$ 필터는 총 27개($3^3$)의 숫자를 가집니다. 필터의 각 숫자를 이미지의 대응하는 위치(R G B 채널 각각)의 숫자와 곱한 뒤 이 27개의 값을 모두 더하여 하나의 결과값을 만듭니다.

**이동 및 출력:**  
필터를 한 칸씩 이동(슬라이딩)하며 이 과정을 반복하면 $6 \times 6 \times 3$ 이미지와 $3 \times 3 \times 3$ 필터의 합성곱 결과로 $4 \times 4$ 크기의 2D 결과물(채널 수 1)을 얻게 됩니다.

### 3. 필터의 활용 예시
필터 내부의 값을 어떻게 설정하느냐에 따라 검출할 수 있는 특성이 달라집니다.

**특정 채널의 특성 검출:**  
빨간색 채널(R) 부분에만 윤곽선 검출 값을 넣고 초록(G)과 파랑(B) 채널을 0으로 채우면 빨간색 채널의 수직 윤곽선만 검출할 수 있습니다.

**전체 채널의 특성 검출:**  
세 채널 모두에 윤곽선 검출 값을 넣으면 색상과 관계없이 이미지 전체의 윤곽선을 검출할 수 있습니다.

### 4. 다중 필터(Multiple Filters) 사용
하나의 이미지에서 여러 가지 특성(예: 수직 윤곽선과 수평 윤곽선)을 동시에 검출하는 방법이다.

**복수 필터 적용:**  
수직 윤곽선 검출 필터와 수평 윤곽선 검출 필터 등 여러 개의 필터를 동시에 사용할 수 있습니다.

**결과 쌓기(Stacking):**  
첫 번째 필터의 결과($4 \times 4$)와 두 번째 필터의 결과($4 \times 4$)를 차곡차곡 쌓아서 합칩니다. 이렇게 하면 결과물은 $4 \times 4 \times 2$의 입체형 부피를 가지게 됩니다.

**결과 차원의 의미:**  
여기서 마지막 숫자 2는 사용된 필터의 개수를 의미한다.

### 5. 일반화된 공식 및 용어 정리
입체형 합성곱의 크기 계산 공식과 용어에 대한 정리이다.

**차원 계산 공식:**  
$n \times n \times n_c$ (입력)와 $f \times f \times n_c$ (필터)를 합성곱할 때 필터의 개수가 $n_{c'}$개라면 결과물의 크기는 $(n-f+1) \times (n-f+1) \times n_{c'}$가 됩니다.

**특성 검출의 확장성:**  
이 방식을 통해 10개 128개 혹은 수백 개의 다양한 특성을 동시에 검출할 수 있으며 결과물의 채널 수는 검출하려는 특성의 수(필터의 수)와 같아집니다.

**용어 주의사항:**  
문맥에 따라 '채널(Channels)'을 '깊이(Depth)'라고 부르기도 하지만 신경망 전체의 깊이(Layer의 깊이)와 혼동될 수 있으므로 이 강의에서는 **채널**이라는 용어를 주로 사용한다.

이 강의는 입체형 데이터에서 합성곱을 수행하는 원리를 설명함으로써 다음 단계인 합성곱 신경망(CNN)의 한 층(Layer)을 구현할 준비를 마치는 데 목적이 있습니다.


## C4W1L07 One Layer of a Convolutional Net

### **1. 합성곱 신경망의 한 계층(Layer) 구성 과정**
**연산 순서:**  
이전 영상의 예시(3D 입체형 입력)를 바탕으로 입력값에 필터를 적용하여 합성곱 연산을 수행한다.

**편향(Bias)과 비선형성(Non-linearity):**  
합성곱 결과에 편향(실수)을 더하고(파이썬의 브로드캐스팅 기능 활용) ReLU와 같은 비선형 함수를 적용한다.

**출력 쌓기:**  
각 필터마다 생성된 결과(예: $4 \times 4$)를 차곡차곡 쌓아서 최종 출력을 만듭니다. 예를 들어 필터가 2개라면 $4 \times 4 \times 2$의 출력이 생성되며 이것이 CNN의 한 계층이 됩니다.

### **2. 표준 신경망과의 비교 (Analogy)**
표준 신경망에서 $z^{} = w^{}a^{} + b^{}$ 계산 후 활성화 함수 $g(z^{})$를 적용하여 $a^{}$을 얻는 것과 원리가 같습니다.
CNN에서는 **필터**가 가중치 $w$와 유사한 역할을 하며 합성곱 연산이 선형 연산($w \cdot a$)에 해당한다. 여기에 편향 $b$를 더하고 비선형성을 적용하여 다음 층의 입력이 될 활성값(activation)을 만듭니다.

### **3. 필터의 개수와 출력의 깊이**
출력 데이터의 채널(깊이) 수는 해당 계층에 사용된 **필터의 개수**와 동일한다. 예를 들어 10개의 필터를 사용하면 출력의 크기는 $4 \times 4 \times 10$이 됩니다.

### **4. 매개변수(Parameter) 개수 계산 (중요)**
**예시:**  
$3 \times 3 \times 3$ 크기의 필터 10개를 사용하는 경우를 가정해 봅니다.

**계산:**  
하나의 필터는 27개의 가중치($3 \times 3 \times 3$)와 1개의 편향을 가져 총 28개의 변수를 가집니다. 필터가 10개이므로 총변수의 수는 $28 \times 10 = 280$개이다.

**특징:**  
입력 이미지의 크기가 $1000 \times 1000$이든 $5000 \times 5000$이든 상관없이 **매개변수의 수는 고정**되어 있습니다. 이는 적은 수의 변수로 큰 이미지를 처리할 수 있게 하여 과대적합(Overfitting)을 방지하는 CNN의 중요한 성질이다.

### **5. CNN 계층의 표기법(Notation) 정리**
이 강의에서는 $l$번째 계층에 대한 표기법을 다음과 같이 정의하고 사용한다.

**필터 크기:**  
$f^{[l]} \times f^{[l]}$.

**패딩과 스트라이드:**  
$p^{[l]}$ (패딩) $s^{[l]}$ (스트라이드).

**입력 크기:**  
$n_H^{[l-1]} \times n_W^{[l-1]} \times n_C^{[l-1]}$ (이전 계층의 출력값).

**출력 크기 (높이/너비):**  
$n_H^{[l]} = \lfloor \frac{n_H^{[l-1]} + 2p^{[l]} - f^{[l]}}{s^{[l]}} + 1 \rfloor$ (너비 $n_W^{[l]}$도 동일 방식).

**출력 크기 (채널):**  
$n_C^{[l]}$ = 해당 계층의 필터 개수.

**필터의 차원:**  
각 필터는 $f^{[l]} \times f^{[l]} \times n_C^{[l-1]}$의 크기를 가집니다. (필터의 채널 수는 입력의 채널 수와 일치해야 함).

**활성값(Activation) $a^{[l]}$의 크기:**  
$m$개의 배치(batch) 데이터가 있을 경우 $m \times n_H^{[l]} \times n_W^{[l]} \times n_C^{[l]}$.

**가중치($W^{[l]}$)의 총 크기:**  
$f^{[l]} \times f^{[l]} \times n_C^{[l-1]} \times n_C^{[l]}$ (필터 개수만큼 곱함).

**편향($b^{[l]}$)의 크기:**  
$(1 1 1 n_C^{[l]})$.

### **6. 데이터 배치 순서의 관례**
강의에서는 높이($H$) 너비($W$) 채널($C$) 순서를 따르지만 일부 오픈소스 코드나 논문에서는 채널을 가장 앞에 두기도 한다($C H W$). 두 방식 모두 통용되므로 코드 분석 시 주의가 필요한다.

## C4W1L08 Simple Convolutional Network Example

### **1. 입력 데이터 및 문제 정의**
**목표:**  
이미지를 입력받아 해당 이미지가 고양이인지 아닌지(0 또는 1)를 분류하는 문제이다.

**입력 이미지(Input):**  
계산 편의를 위해 비교적 작은 크기인 **39 x 39 x 3** 이미지를 사용한다(높이와 너비 39 채널 수 3).

### **2. 첫 번째 합성곱 층 (Layer 1)**
**설정:**  
3x3 필터($f^{}=3$) 스트라이드 1($s=1$) 패딩 없음(valid convolution) 필터 개수 10개를 사용한다.

**결과:**  
공식($\frac{n+2p-f}{s} + 1$)에 따라 37 x 37 크기가 되며 필터가 10개이므로 최종 출력 크기는 **37 x 37 x 10**이 됩니다.

### **3. 두 번째 합성곱 층 (Layer 2)**
**설정:**  
5x5 필터($f^{}=5$) **스트라이드 2($s=2$)** 패딩 없음 필터 개수 20개를 적용한다.

**결과:**  
스트라이드가 2이기 때문에 크기가 급격히 줄어들어 **17 x 17 x 20**의 출력 크기를 가집니다.

### **4. 세 번째 합성곱 층 (Layer 3)**
**설정:**  
5x5 필터 스트라이드 2 패딩 없음 필터 개수 40개를 적용한다.

**결과:**  
최종적으로 **7 x 7 x 40** 크기의 특성 맵(feature map)이 생성됩니다.

### **5. 펼치기(Flatten) 및 예측**
**펼치기:**  
마지막 층의 결과인 7 x 7 x 40의 텐서를 모두 펼쳐서 **1960개의 요소를 가진 하나의 긴 벡터**로 만듭니다.

**예측:**  
이 벡터를 로지스틱 회귀 유닛이나 소프트맥스 유닛에 입력하여 최종 확률값(고양이인지 아닌지 등)을 예측한다.

### **6. CNN 구조의 일반적인 경향**
신경망이 깊어질수록 **이미지의 높이와 너비($n_H n_W$)는 줄어들고(39 -> 37 -> 17 -> 7) 채널의 수($n_C$)는 늘어나는(3 -> 10 -> 20 -> 40)** 경향을 보이다.
합성곱 신경망 디자인은 필터 크기 스트라이드 패딩 등과 같은 하이퍼파라미터를 결정하는 과정이다.

### **7. 신경망 층(Layer)의 종류 소개**
일반적인 합성곱 신경망은 다음 세 가지 종류의 층으로 구성됩니다.
1.  **합성곱 층 (Convolution CONV):**  
    이번 영상에서 다룬 층이다.
2.  **풀링 층 (Pooling POOL):**  
3.  **완전 연결 층 (Fully Connected FC):**  


## C4W1L09 Pooling Layers
### **1. 풀링 층(Pooling Layers)의 목적과 기본 원리**
**목적:**  
합성곱 신경망(CNN)에서 풀링 층을 사용하면 표현(representation)의 크기를 줄여 **계산 속도를 높이고** 주요 특성(feature)을 더 잘 검출해낼 수 있습니다.

**최대 풀링(Max Pooling) 예시:**  
4x4 크기의 입력을 2x2 크기로 줄이는 경우를 예로 들면 입력을 4개의 영역(구역)으로 나누고 각 영역에서 **최댓값**만을 취하여 출력값을 만듭니다.

**작동 방식:**  
이는 마치 필터 크기($f$)를 2 스트라이드($s$)를 2로 설정하여 필터를 적용하는 것과 같습니다.

### **2. 최대 풀링의 직관적 의미**
**특성 감지:**  
입력값의 숫자를 특정 특성(예: 세로 윤곽선이나 고양이의 눈)이 발견된 정도라고 가정할 때 숫자가 클수록 해당 특성이 강하게 존재함을 의미한다.

**정보 보존:**  
최대 풀링은 필터 영역 내에서 특성이 발견되면(높은 숫자가 있으면) 그 값을 남기고 특성이 없으면 작은 값을 남깁니다. 즉 **주요 특성이 존재한다는 정보를 유지**하면서 데이터 크기를 줄이는 역할을 한다.

**특징:**  
최대 풀링은 많은 실험에서 좋은 성능을 보여주며 가장 큰 특징은 **학습해야 할 파라미터(변수)가 없다**는 점이다. $f$와 $s$는 고정된 하이퍼파라미터이므로 경사 하강법으로 학습되지 않습니다.

### **3. 다양한 하이퍼파라미터와 3차원 입력 처리**
**공식:**  
풀링 층의 출력 크기는 합성곱 층과 동일한 공식 $\lfloor \frac{n+2p-f}{s} + 1 \rfloor$을 사용하여 계산할 수 있습니다.

**채널 처리:**  
입력 데이터가 3차원(예: $5 \times 5 \times n_c$)일 경우 풀링은 **각 채널에 독립적으로 적용**됩니다. 따라서 입력의 채널 수와 출력의 채널 수는 동일하게 유지됩니다.

### **4. 평균 풀링(Average Pooling)과 일반적인 설정**
**평균 풀링:**  
최댓값 대신 필터 영역 내 값들의 **평균**을 구하는 방식이다. 하지만 최근에는 최대 풀링이 훨씬 더 많이 사용됩니다.
    *예외:* 신경망의 매우 깊은 층에서 7x7 같은 크기를 1x1로 줄일 때 가끔 사용됩니다.

**자주 쓰이는 설정:**  
가장 일반적인 하이퍼파라미터 설정은 **$f=2 s=2$**이며 이는 높이와 너비를 절반으로 줄이는 효과가 있습니다. 패딩($p$)은 풀링 층에서는 거의 사용하지 않으므로 보통 0이다.

### **5. 결론 및 요약**
풀링 층은 학습할 변수가 없는 **고정된 함수**이다. 역전파를 통해 업데이트될 가중치가 없으며 하이퍼파라미터($f s$ 풀링 종류)만 설정하면 됩니다.



## C4W1L10 CNN Example
고전적인 신경망 모델인 **LeNet-5**와 유사한 구조를 구축하는 과정을 영상의 시간 순서대로 정리해 드립니다.

### **1. 예제 설정 및 입력 데이터**
**목표:**  
0부터 9까지의 손글씨 숫자를 인식하는 것이다.

**입력:**  
32x32 픽셀 크기의 RGB 이미지(32 x 32 x 3)를 사용한다.

**모델 배경:**  
얀 르쿤(Yann LeCun)이 개발한 고전적인 'LeNet-5' 구조에서 영감을 받아 변수들을 설정한다.

### **2. Layer 1: 첫 번째 합성곱 및 풀링 층**
**CONV1 (합성곱):**  
5x5 필터 스트라이드(stride) 1 패딩(padding) 없음 필터 개수 6개를 적용한다. 결과적으로 이미지 크기는 28x28x6이 됩니다.

**POOL1 (풀링):**  
2x2 필터 스트라이드 2를 사용하는 최대 풀링(Max Pooling)을 적용한다. 높이와 너비가 절반으로 줄어들어 14x14x6이 됩니다.

**층(Layer)의 정의:**  
신경망에서 '층'의 개수를 셀 때 학습 가능한 가중치(weight)가 있는 층만 세는 것이 일반적인 관습이다. 풀링 층은 가중치가 없으므로 CONV1과 POOL1을 합쳐서 하나의 'Layer 1'으로 간주한다.

### **3. Layer 2: 두 번째 합성곱 및 풀링 층**
**CONV2:**  
5x5 필터 스트라이드 1 패딩 없음 필터 개수 16개를 적용한다. 출력 크기는 10x10x16이 됩니다.

**POOL2:**  
다시 한번 2x2 스트라이드 2의 최대 풀링을 적용하여 크기를 절반인 5x5x16으로 줄이다.

**펼치기 (Flatten):**  
5x5x16의 텐서를 400개(5x5x16=400)의 유닛을 가진 1차원 벡터로 펼칩니다. 이는 다음 단계인 완전 연결 층으로 넘어가기 위함이다.

### **4. Layer 3 & 4: 완전 연결 층 (Fully Connected Layer) 및 출력**
**FC3:**  
펼쳐진 400개의 입력 유닛을 120개의 유닛을 가진 층과 완전히 연결(Fully Connected)한다. 이 층은 표준 신경망과 유사하게 동작한다.

**FC4:**  
120개의 유닛을 다시 84개의 유닛을 가진 층으로 연결한다.

**Softmax (출력):**  
마지막으로 10개의 숫자(0~9)를 분류하기 위해 10개의 출력을 가진 소프트맥스(Softmax) 유닛에 연결한다.

### **5. CNN 구조의 일반적인 패턴과 파라미터**
**구조적 패턴:**  
전형적인 CNN은 [합성곱 층 → 풀링 층]을 몇 번 반복하다가 마지막에 [완전 연결 층 → 소프트맥스]로 이어지는 구조를 가집니다.

**크기 변화:**  
신경망이 깊어질수록 높이와 너비($n_H n_W$)는 줄어들고(32→28→14→10→5) 채널(Channel)의 수는 늘어나는(3→6→16) 경향이 있습니다.

**파라미터 분포:**  
풀링 층은 파라미터가 0개이며 합성곱 층은 비교적 적은 파라미터를 가집니다. 대부분의 파라미터는 완전 연결 층(FC)에 집중되어 있습니다.

**활성값 크기:**  
활성값의 크기(Activation size)는 신경망이 깊어질수록 점진적으로 감소해야 하며 너무 급격하게 줄어들면 성능에 좋지 않을 수 있습니다.

이 강의는 이러한 구성 요소들을 어떻게 조합하여 효율적인 신경망을 만드는지에 대한 직관을 제공하며 다음 강의에서는 다른 연구자들이 개발한 구체적인 아키텍처 사례들을 살펴볼 것임을 예고하며 마무리됩니다.


## C4W1L11 Why Convolutions

### **1. 완전 연결 층(Fully Connected Layer) vs 합성곱 층(Convolutional Layer)**
**변수 폭증 문제:**  
32x32x3 크기의 이미지를 28x28x6 크기의 출력으로 변환하는 경우를 가정해 봅니다.  
    **완전 연결 층:**  
    입력 유닛(3072개)과 출력 유닛(4704개)을 모두 연결하면 가중치 행렬의 크기가 약 **1400만 개**에 달한다. 이미지가 조금만 커져도(예: 1000x1000) 변수가 감당할 수 없을 정도로 많아집니다.  
    **합성곱 층:**  
    반면 5x5 필터 6개를 사용한다고 가정하면 필터당 26개의 변수(가중치 25 + 편향 1)만 필요하므로 총 변수는 **156개**에 불과한다.

**결론:**  
합성곱 층은 변수의 수를 획기적으로 줄여주며 그 핵심 이유는 **변수 공유**와 **희소 연결** 두 가지이다.

### **2. 합성곱의 두 가지 핵심 이점**
**변수 공유 (Parameter Sharing):**  
이미지의 특정 부분(예: 왼쪽 위)에서 유용한 특징 검출기(예: 세로 윤곽선 검출기)는 이미지의 다른 부분(예: 오른쪽 아래)에서도 똑같이 유용할 가능성이 높습니다. 따라서 위치마다 다른 필터를 학습할 필요 없이 동일한 필터(변수)를 이미지 전체에 공유하여 사용한다.

**희소 연결 (Sparsity of Connections):**  
합성곱 연산의 결과값(출력 픽셀 하나)은 입력 이미지의 전체 픽셀이 아니라 필터가 덮고 있는 작은 영역(예: 3x3 또는 5x5)의 픽셀들에만 영향을 받습니다. 나머지 픽셀들과는 연결되지 않으므로 과대적합(Overfitting)을 방지하고 계산량을 줄이는 데 도움을 줍니다.

### **3. 이동 불변성 (Translation Invariance)**
합성곱 신경망은 이미지가 몇 픽셀 이동하더라도 대상을 잘 인식할 수 있는 '이동 불변성'을 포착하는 데 용이한다.
예를 들어 고양이 사진이 옆으로 조금 이동해도 여전히 고양이로 인식해야 하는데 합성곱 층은 동일한 필터를 모든 위치에 적용하기 때문에 이러한 특성을 자동으로 학습할 수 있습니다.

### **4. 합성곱 신경망의 훈련 (Training)**
**구조:**  
이미지 입력 $\rightarrow$ 합성곱 및 풀링 층 반복 $\rightarrow$ 완전 연결 층 $\rightarrow$ 소프트맥스(Softmax) $\rightarrow$ 예측값 $y$ 출력의 구조를 가집니다.

**학습 과정:**
1.  파라미터 $W$와 $b$를 무작위로 초기화한다.
2.  훈련 세트에 대한 예측값과 실제값의 차이(비용 함수 $J$)를 계산한다.
3.  경사 하강법(Gradient Descent) 모멘텀(Momentum) RMSprop 등의 최적화 알고리즘을 사용하여 비용 함수 $J$를 최소화하는 방향으로 파라미터를 업데이트한다.




