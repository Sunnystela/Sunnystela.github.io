---
layout: post
title:  "[CV] 눈감지마!"
date:   2025-02-07 17:17
categories: project CV 
tag: CV
---

## 정리리

### 0️⃣ 프로젝트를 나타낼 수 있는 이미지를 올려주세요!

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/b9ddad24-6554-47ec-ad56-45f61bc9afd6/7c15f268-f930-439c-b4bd-b1fb6a33c07a/image.png)

## 1️⃣ 이런 프로젝트를 진행하고 싶어요!

<aside> 💡 진행하고 싶은 프로젝트의 주제를 **구체적**으로 작성해도 좋고, **대략적**으로 이런 방향, 느낌의 프로젝트를 진행할 계획이다 정도로 작성해도 좋습니다!

</aside>

### 프로젝트 배경

- 행사, 졸업식처럼 많은 사람들과 함께 사진을 촬영하는 경우, 누군가는 눈을 감거나, 반쯤 감긴 상태로 찍히는 경우가 종종 발생.
- 또한, 중요한 순간이나 한정된 시간에 많은 사람들과 함께 촬영하는 경우 매번 사진을 확인할 수도 없고 재촬영해야 하는 번거로움 및 불편 발생 => 이에 사진 촬영 시, 실시간으로 사람들의 눈 감김을 감지하고 사진 촬영 시 즉각적으로 알림을 제공하는 시스템을 통해 사진 촬영의 효율성 향상에 기여. 재촬영의 번거로움을 줄임
- 이미 한 명의 눈을 감지하는 서비스는 존재한다. 이와 다르게 여러 명의 단체 사진을 찍을 때에도 모두가 눈을 뜬 찰나를 감지할 수 있는 더 개선된 서비스를 만들 예정

### 프로젝트 방향

- 목표: 단체 사진 촬영 시 실시간으로 여러 명의 사용자 눈 감김 상태를 감지하여 촬영의 정확성과 편의성을 높이는 AI 기술을 도입.
- YOLO 기반의 객체 탐지 모델을 활용해 얼굴과 눈을 빠르게 인식하고, MobileNet 기반의 눈 상태 분류 모델을 통해 눈이 감긴 상태인지 실시간으로 감지할 수 있도록 한다. 또한, 필요 시 LSTM 기반의 시간 분석 모델을 결합해 눈 감김 상태가 일정 시간 이상 지속될 경우 즉각적으로 알림을 제공하여 촬영을 원활하게 진행하도록 돕는다.

## 2️⃣ 이런 팀원들과 함께하고 싶어요!

<aside> 💡

**프로젝트를 같이 하고 싶은 팀원**이 어떤 팀원인지 써주세요! 팀 빌딩은 꼭 선착순이 아니라, 대부분 서로 합을 이루어서 만들어지다보니 **내용을 자세하게** 써주시면 프로젝트 팀을 고를 때 다른 분들도 많은 도움이 되겠죠⁉️

***팀원을 어떻게 뽑을지 (트랙 내에서만 모집, 선착순, 개별 연락 등)는 필수 입력 사항으로 적어주세요!**

</aside>

모집완료

## 3️⃣ 프로젝트를 이런 식으로 진행할 예정이에요!

<aside> 💡

프로젝트 팀의 분위기, 규칙을 써도 좋습니다! 자세한 **일정**이나 **협업 방식, 시간, 사용할 개발 툴** 등도 언급해주시면 좋을 것 같습니다😊

</aside>

---

**1. 데이터셋 구성**

- Dataset:. Closed Eyes in the Wild (CEW), CelebA Dataset, RLDD (Real-Life Drowsiness Dataset) 등 눈 감김 상태와 눈 뜬 상태가 모두 포함된 얼굴 이미지를 수집하여 Dataset 구축. (만약 데이터가 부족하다면 크롤링으로 이미지 수집 예정)

**2. 데이터 전처리**

- 얼굴 및 눈 영역 추출: OpenCV와 YOLO, dlib를 사용한다. YOLO를 통해 얼굴 및 눈 영역을 추출한 뒤, dlib(얼굴 랜드마크 검출기. 얼굴 랜드마크의 좌표를 제공하는 데에 사용)로 눈의 좌표를 정확하게 파악하는 방식으로 모델 학습에 필요한 데이터를 구성
- 데이터 정규화 및 조정: 이미지의 크기와 비율을 일관되게 조정, 모델이 일관된 입력 데이터 학습
- 라벨링 작업: 눈이 감긴 상태와 뜬 상태를 구분하여 데이터 라벨링
- 데이터 증강: 데이터셋에 부족한 조명, 각도, 거리 변화 등을 반영하기 위해 다양한 이미지 증강 기법을 적용해 데이터의 다양성 향상

**3. 모델 학습**

- 눈 감김 상태 분류 모델 (MobileNet 활용): MobileNet을 사용하여 눈 영역에서 눈 감김 상태를 감지하는 경량 모델 학습 및 수집한 데이터셋을 학습하고 검증하여, 눈 감김 감지 정확도를 최적화
- 얼굴 및 눈 검출 모델 (YOLO 활용): 얼굴과 눈을 빠르고 정확하게 실시간으로 검출하기 위해 YOLO 모델을 학습하여 사용자의 눈 영역을 분리하여 MobileNet 분류 모델에 전달

**4. 모델 평가 및 검증**

- 성능 평가: 눈 감김 상태 감지 정확도와 YOLO를 통한 얼굴 및 눈 검출 속도를 평가하여, 실시간 감지 시스템으로서의 성능 확인
- 검증: 다양한 조명, 각도, 환경 조건에서 테스트하여 실사용 환경에서도 모델이 안정적으로 작동하는지 검증

**5. 개발툴 및 협업방식**

- 협업방식: 대면 및 ZOOM 활용
    
- 개발툴: PyTorch, OpenCV, YOLO, Pillow, Scikit-learn 등
    

## 4️⃣ 확정 팀원 입력 칸입니다! 조장 전용

<aside> 💡 **프로젝트를 같이 하기로 확정된 팀원들**만 프로젝트 제안자가 직접 아래 테이블에 추가해주세요!

2명 이상의 팀프로젝트를 권장하며, 트랙별 제한 인원이나 트랙을 섞어서 팀을 구성하는 것에 대해 아무런 제한사항이 없습니다.

</aside>

[Untitled](https://www.notion.so/85fe34af27ac4792adad5b0f81f8717b?pvs=21)



---
프로젝트 

노션
https://www.notion.so/12778008bf5880549859d87efa35ce8f

깃허브
https://github.com/ye-ram/KHUDA
