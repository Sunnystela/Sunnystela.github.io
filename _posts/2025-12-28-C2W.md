---
layout: post
title: "[DeepLearning.AI] 2. Improving Deep Neural Networks"
date: 2025-12-27 23:50
categories: MyStudy DeepLearning.AI
tags: DeepLearning.AI DeepLearning
math: true
---
## Train/Dev/Test Sets (C2W1L01)

모델의 성능을 효율적으로 개선하기 위한 **데이터 세트(훈련, 개발, 테스트 세트) 설정 방법**

### 1. 반복적인 과정 
**초기 설정의 어려움:** <br>layer 개수, hidden unit 수, 학습률, 활성화 함수 등 수많은 하이퍼파라미터의 최적값을 처음부터 완벽하게 추측하는 것은 거의 불가능

**반복 순환(Cycle):** <br>  **'Idea -> Code -> Experiment'** 의 사이클을 반복하며 모델을 개선해 나가는 과정. 얼마나 효율적으로 빠르게 돌 수 있느냐가 좋은 모델을 만드는 핵심이다. 데이터를 잘 설정하면 이 과정을 빠르게 할 수 있다.

### 2. 데이터 세트의 구성과 역할
**전통적인 구성:** <br>전체 데이터를 훈련(Train), 개발(Dev, 또는 교차 검증 세트), 테스트(Test) 세트로 나눈다.
1.  **훈련 세트:** 알고리즘을 학습
2.  **개발(Dev) 세트:** 다양한 모델 중 어떤 것이 가장 성능이 좋은지 평가하고 선택
3.  **테스트 세트:** 최종 선택된 모델의 성능을 편향 없이 측정

### 3. 데이터 세트 비율의 변화 
**과거:** <br>데이터가 적었을 떄는 **60/20/20%** (훈련/개발/테스트) 또는 **70/30%** (훈련/테스트) 비율로 나누는 것이 일반적이었다.

**현대:** <br>데이터가 100만 개 이상인 경우 개발 및 테스트 세트는 굳이 전체의 20%를 할당할 필요가 없다.비율은 **98/1/1%** 혹은 **99.5/0.25/0.25%** 와 같이 훈련 세트에 많은 비중을 둔다.

### 4. 데이터 Distribution 불일치
훈련 데이터와 테스트 데이터의 출처(분포)가 다른 경우가 많다.
>훈련 데이터는 웹에서 긁어온 고화질 고양이 사진(많은 양)이지만 실제 앱 서비스에서 분류해야 할 개발/테스트 데이터는 사용자가 폰으로 찍은 저화질 사진(적은 양)일 수 있다.

**핵심 원칙:** <br>훈련 데이터는 다른 분포에서 가져오더라도 **Dev 세트와 Test 세트는 same distribution에서 가져와야 한다.** 이는 개발 세트에서 목표로 삼은 성능 지표가 실제 테스트 환경에서도 유효하도록 하기 위함.

### 5. 테스트 세트의 생략 가능성
**테스트 세트의 목적:** 최종 모델 성능에 대한 편향 없는 추정치를 얻는 것.

**테스트 세트가 없는 경우:** <br>만약 편향 없는 추정치가 굳이 필요 없다면 테스트 세트 없이 **훈련/개발 세트**만으로 구성해도 된다.
종종 개발 세트를 '테스트 세트'라고 부르지만 실제로는 개발 세트에 맞춰 모델을 튜닝(과적합)하고 있으므로 개발 세트입니다.




## Bias/Variance (C2W1L02)

**편향(Bias)과 분산(Variance)** 을 훈련 세트와 개발 세트의 오차율을 통해 분석하는 방법

### 1. 편향과 분산 (2차원 데이터)
딥러닝 시대에는 '편향-분산 트레이드오프'에 대한 논의는 줄었지만, 여전히 오류를 진단하는 핵심 도구이다.

![alt](/assets/img/c2w.bias.png)

**High Bias:** **과소적합(Underfitting)**
>데이터는 곡선 분포인데 직선으로 분류하려는 로지스틱 회귀

**적절함 (Just Right):** 편향과 분산 사이의 균형을 찾아 데이터의 패턴을 잘 설명하는 상태

**높은 분산 (High Variance):**  **과대적합(Overfitting)**
>모든 훈련 데이터를 완벽하게 통과하려고 지나치게 복잡하게 구부러진 신경망


### 2. 고차원 데이터에서의 진단 지표 (훈련 세트 vs 개발 세트)
고차원 데이터는 시각화할 수 없으므로 **훈련 세트 오차(Train Set Error)** 와 **개발 세트 오차(Dev Set Error)** 두 가지 숫자를 비교한다. 이때 **인간 수준의 성능(베이즈 오차)이 0%에 가깝다고 가정**

*   **High Variance**
    *   훈련 오차 1%, 개발 오차 11%.
    *   훈련 세트는 매우 잘 맞추지만, 보지 못한 개발 세트에서는 성능이 떨어진다. 훈련 데이터에 **과대적합**되어 일반화에 실패

*   **High Bias**
    *   훈련 오차 15%, 개발 오차 16%.
    *   훈련 세트조차 제대로 맞추지 못하고 있다. 데이터에 **과소적합**된 상태. 

*   **High Bias & High Variance**
    *   훈련 오차 15%, 개발 오차 30%.
    *   훈련 세트도 잘 맞추지 못하고(높은 편향), 개발 세트에서는 오차가 훨씬 더 커진다(높은 분산). 최악

*   **low Bias & low Variance**
    *   훈련 오차 0.5%, 개발 오차 1%.
    *   훈련 세트도 잘 맞추고 일반화도 잘 된 이상적인 상태.

**훈련 세트 오차**를 통해 알고리즘이 데이터에 얼마나 잘 적합하는지(편향 문제)를 본다.<br>
**훈련 오차와 개발 오차의 차이**를 통해 분산 문제(일반화 성능)가 얼마나 심각한지 파악한다.

### 3. High Bias & High Variance
![alt](/assets/img/c2w.highbias.png)

전체적으로는 데이터의 경향을 따르지 못하는 선형 모델(높은 편향)이면서 동시에 몇몇 outlier나 특정 샘플을 맞추기 위해 국소적으로 심하게 구불거리는(높은 분산) 형태.

일부 영역에서는 과소적합되고, 다른 영역에서는 과대적합되는 현상이 발생할 수 있다.

