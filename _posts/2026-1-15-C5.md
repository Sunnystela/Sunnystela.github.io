---
layout: post
title: "수정중. [DeepLearning.AI] Course 5추가 of the Deep Learning Specialization"
date: 2026-01-25 12:50
categories: MyStudy DeepLearning.AI
tags: DeepLearning.AI DeepLearning
math: true
---

[Sequence Models (Course 5 of the Deep Learning Specialization)](https://www.youtube.com/watch?v=_i3aqgKVNQI&list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6)


### **4. 딥러닝 모델 아키텍처**
음성 인식을 위해 **Attention model**을 사용하거나 **CTC(Connectionist Temporal Classification) 비용 함수**를 활용할 수 있다.

실제 구현 시에는 단방향 RNN보다는 주로 **양방향 LSTM(Bidirectional LSTM)이나 GRU**와 같은 깊은 모델을 사용한다.

### **5. CTC(Connectionist Temporal Classification)의 원리**
음성 인식에서는 입력 타임 스텝(예: 1000개)이 출력 캐릭터 수(예: 19개)보다 훨씬 많은 것이 일반적이다.

**CTC 비용 함수**는 이를 해결하기 위해 **특수 문자 blank**와 **반복된 문자를 하나로 합치는 규칙**을 사용한다.
>"TTT_h_eee"라는 출력이 있다면 blank(_)가 없는 구간의 반복된 글자를 합쳐 "The"로 변환한다.

이 방식을 통해 수천 개의 출력 값을 가지는 신경망이 훨씬 짧은 텍스트 스크립트를 효과적으로 표현할 수 있다.

현재 프로덕션 수준의 음성 인식 시스템을 구축하는 것은 매우 방대한 데이터가 필요한 큰 작업이다.





>blank를 어차피 합치는데 왜필요한가
{: .prompt-warning }

**연속된 같은 문자**:  
CTC의 핵심 규칙은 연속된 같은 문자를 하나로 합치는 것이다. 만약 blank가 없다면 'apple'이나 'hello'처럼 같은 문자가 연달아 나오는 단어를 인식할 수 없다.

blank가 없을 때: ppple → ple (p가 하나로 합쳐짐)  
blank가 있을 때: pp-pple → p-ple → pple (중간에 blank가 있어 p가 합쳐지지 않음)

blank는 똑같은 소리가 반복될 때 이를 별개의 문자로 떼어놓는 구분자 역할을 한다.



**Time Step 정렬**:  
음성 데이터는 텍스트에 비해 데이터의 길이가 압도적으로 길다. 1초의 짧은 말소리도 수백 개의 프레임으로 쪼개지는데 모델은 모든 프레임마다 반드시 결과값을 내놓아야 한다.

의미 없는 구간 처리: 숨소리, 침묵, 혹은 소리와 소리 사이의 모호한 전이 구간에서 억지로 글자를 출력할 수 없으므로 blank를 채워 넣다.

길이 조절: 수백 개의 출력값 중 실제 글자가 있는 위치를 제외한 나머지를 blank로 채움으로써 입력 음성과 출력 텍스트 사이의 길이 차이를 수학적으로 해결한다.


>연음같은 거 깔끔하게 안끊기는거 같은데 어떻게 나누는지
{: .prompt-warning }


CTC는 음성 데이터의 경계를 물리적으로 나누지 않고 **모든 시간 단위에서 예측된 결과를 사후에 하나로 뭉치는 'Many-to-One' 매핑 방식**으로 연음 문제를 해결한다.

CTC는 사람이 일일이 경계를 나누는 대신 가능한 모든 경우의 수를 수학적으로 합산하는 방식이다.

강제 분할 과정을 생략한다:  
학습을 위해 모든 음성 데이터의 프레임마다 정답 라벨을 일일이 달아줘야 했다. 하지만 CTC는 이 번거로운 작업을 포기하고 대신 모델이 스스로 전체 시퀀스 안에서 정답을 찾아가도록 내버려 두는 방식을 사용한다.

모든 경로 허용:  
중복 제거와 Blank규칙을 사용하여 
입력 시퀀스의 각 타임스텝마다 발생할 수 있는 모든 문자의 확률을 더하는 방식으로 계산한다.

연음이 발생하여 한 문자가 끝나고 다음 문자로 넘어가는 시점이 깔끔하지 않을 때 blank로 넘긴다


CTC는 사람이 직접 나누기 어려운 모호한 경계를 모든 가능한 정렬의 확률 합이라는 개념으로 우회하여 해결힌다. 어떻게 나누냐는 질문에 대한 CTC의 답은 직접 나누지 않고 발생 가능한 모든 나눗셈의 경우의 수를 다 고려한다가 된다.


>space는 왜 필요한가
{: .prompt-warning }


**space는 단어와 단어를 구분하는 실제 텍스트 구성 요소**이기 때문에 필요하다.

---

### 1. 언어적 의미의 구분

**blank**는 모델이 연산을 위해 사용하는 가상의 기호일 뿐, 최종 결과물에서는 사라집니다. 반면 **space**는 우리가 읽는 문장에서 'the'와 'quick'을 'thequick'이 아닌 'the quick'으로 나누어주는 **실제 문자**이다. 모델 입장에서는 'a', 'b', 'c'와 마찬가지로 학습해야 할 하나의 클래스(Class)이다.

### 2. Blank와 Space의 역할 차이

둘은 완전히 다른 목적으로 사용됩니다.

* **Blank ( _ ):** 기술적 도구이다. 같은 문자가 연속될 때(예: apple의 pp) 이들을 합치지 않게 막아주거나, 음성 신호가 없는 구간을 채우는 역할을 한다. 결과 출력 시에는 모두 제거됩니다.
* **Space ( ):** 언어적 도구이다. 단어 사이의 공백을 나타내며, 결과 출력 시에도 문장에 그대로 남아 띄어쓰기를 완성한다.

### 3. 모델의 예측 예시

만약 "the quick"이라는 음성이 들어왔을 때, CTC 모델은 내부적으로 다음과 같이 예측할 수 있다.

> **TTT _ _ HHH EEE _ _ (space) (space) _ _ QQQ UUU...**

이 예측 결과에서 중복을 제거하고 blank( _ )를 지우면 다음과 같이 남다.

> **T H E (space) Q U I C K**

만약 여기서 space가 없다면 모델은 단어 사이의 경계를 알 수 없어 모든 글자를 붙여서 출력하게 됩니다. 즉, **space는 사람이 읽을 수 있는 문장을 만들기 위한 필수 문자**이다.




음성 신호는 끊기지 않고 이어지는 흐름(Continuous signal)인데, 왜 텍스트처럼 **Space(띄어쓰기)**라는 개념이 필요한지

1. 음성에는 없어도 텍스트에는 있어야 하기 때문
우리가 말을 할 때는 단어 사이를 명확히 띄우지 않고 연음으로 이어서 말하는 경우가 많다. 하지만 음성 인식 모델의 결과물인 **Transcript(대본)**는 사람이 읽어야 한다.

Space가 없다면: thequickbrownfox (가독성 최악)

Space가 있다면: the quick brown fox (우리가 아는 문장)

모델은 학습 과정에서 "특정 발음 패턴이 끝날 때쯤 띄어쓰기( )라는 문자가 나온다"는 것을 데이터셋(Label)을 통해 학습하게 됩니다.

2. 단어의 경계를 명확히 구분 (Word Segmentation)
음성 신호 자체에는 명확한 공백이 없더라도, 언어적으로 단어와 단어를 구분해야 문맥 파악이 가능한다.

예: "아버지가방에" -> "아버지가 방에" vs "아버지 가방에" 이처럼 Space는 소리의 물리적 멈춤을 나타내는 것이 아니라, 언어적인 의미의 마디를 나누는 역할을 한다.

3. Blank와 Space의 결정적 차이
질문하신 맥락에서 가장 헷갈리는 부분이 이 지점일 것이다.

Blank (_): CTC 알고리즘이 중복 문자를 합치거나 입력 길이를 맞추기 위해 쓰는 내부 계산용 가상 기호이다. (출력 시 삭제)

Space ( ): 'a', 'b', 'c'와 똑같이 취급되는 실제 문자이다. 모델은 음성 데이터에서 단어 사이의 특징을 찾아내어 이 'Space'라는 글자를 예측하도록 훈련됩니다. (출력 시 유지)

# 일본어 중국어는 공백이 없다?

일본어와 중국어 음성 인식에서는 **space 기호를 학습 대상(Label)에서 제외**한다. 하지만 **blank는 언어의 특성과 상관없이 알고리즘의 작동을 위해 반드시 유지**해야 한다.

---

### 1. Space는 언어적 선택 사항

영어와 한국어는 띄어쓰기가 의미 전달과 가독성에 필수적이므로, 모델에게 space라는 '글자'를 출력하도록 가르칩니다. 반면, 일본어와 중국어는 단어 사이를 띄우지 않는 것이 기본 규칙이다.

* **처리 방식:** 이들 언어를 학습시킬 때는 모델이 내뱉어야 할 정답지에서 space를 아예 빼버립니다. 모델은 단순히 글자와 글자를 이어서 출력하는 법만 배웁니다.
* **참고:** <<확실하지 않은 내용: 특정 연구나 목적에 따라 형태소 분석을 거친 뒤 강제로 공백을 넣어 학습시키는 경우도 있으나, 일반적인 End-to-End 모델에서는 생략한다.>>

### 2. Blank는 수학적 필수 사항

blank는 띄어쓰기가 아니라 **중복을 막는 벽**이자 **시간을 맞추는 도구**이다.

* **중복 글자 보존:** 중국어의 妈妈(māma)처럼 같은 소리가 연속될 때, blank가 없다면 CTC의 합치기 규칙 때문에 'ma' 한 글자로 인식되는 오류가 발생한다. 'ma - blank - ma' 형태의 경로가 있어야만 두 글자를 온전히 보존할 수 있다.
* **음성 길이 대응:** 음성은 긴데 출력할 글자는 적은 물리적 차이를 메꾸기 위해 blank는 반드시 필요한다.

### 3. 언어별 구성 차이 요약

* **영어/한국어:** [문자들] + [space 기호] + [blank 토큰]
* **일본어/중국어:** [문자들] + [blank 토큰] (space 제외)

결론적으로 space는 **우리가 읽기 편하려고 넣는 글자**일 뿐이지만, blank는 **컴퓨터가 음성을 글자로 압축하기 위해 사용하는 엔진의 부품**과 같다.

---

이러한 차이가 실제 일본어/중국어 데이터셋의 전처리(Tokenization) 과정에서 어떻게 구현되는지 궁금하신가요?