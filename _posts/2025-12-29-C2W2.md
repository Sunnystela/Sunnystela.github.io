---
layout: post
title: "[DeepLearning.AI] Course2.W2 Improving Deep Neural Networks"
date: 2025-12-29 11:50
categories: MyStudy DeepLearning.AI
tags: DeepLearning.AI DeepLearning
math: true
---

[Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization (Course 2 of the Deep Learning Specialization)](https://www.youtube.com/watch?v=1waHlpKiNyY&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)

## Mini Batch Gradient Descent (C2W2L01)
### **1. 대규모 데이터와 최적화의 필요성**  
딥러닝은 빅데이터 환경에서 가장 잘 작동하지만, 데이터셋이 클수록 훈련 속도가 느려진다. Vectorization를 사용하면 $m$개의 샘플을 효율적으로 계산할 수 있지만 $m$이 500만 개처럼 매우 큰 경우에는 여전히 처리가 느리다.
### **2. 배치 경사 하강법의 한계와 미니배치 도입**  
기존의 배치 경사 하강법은 단 한 번의 매개변수 업데이트를 수행하기 위해 500만 개의 전체 훈련 데이터를 모두 처리해야 한다. 더 빠른 알고리즘을 위해 전체 훈련 세트를 작은 단위인 **'Mini-batch'** 로 나눈다. 
> 500만 개의 데이터를 1,000개씩 묶어 총 5,000개의 미니배치를 만들 수 있다.

### **3. 표기법(Notation) 정의**
새로운 표기법 $X^{\{t\}}, Y^{\{t\}}$가 도입된다.  
$(i)$: $i$번째 훈련 샘플  
$[l]$: $l$번째 신경망 층  
$\{t\}$: $t$번째 미니배치  
> 미니배치 크기가 1,000이라면 $X^{\{t\}}$의 차원은 $(n_x, 1000)$, $Y^{\{t\}}$의 차원은 $(1, 1000)$이 된다.

### **4. 미니배치 경사 하강법 알고리즘 구조**
전체 데이터를 한 번에 처리하는 '배치 경사 하강법'과 달리 '미니배치 경사 하강법'은 한 번에 하나의 미니배치($X^{\{t\}}, Y^{\{t\}}$)만을 사용하여 학습을 진행한다.

**반복문(Loop):**  
$t=1$부터 5,000까지(미니배치 개수만큼) 반복한다.

**정방향 전파(Forward Propagation):**  
전체 $X$ 대신 $X^{\{t\}}$를 사용하여 입력부터 출력까지 계산한다. 이때 1,000개 샘플에 대해 벡터화된 연산을 수행한다.

**비용 계산(Cost Computation):**  
해당 미니배치에 대한 비용 $J^{\{t\}}$를 계산한다.

**역전파(Backpropagation):**  
$J^{\{t\}}$에 대한 Gradient를 계산한다.

**매개변수 업데이트:**  
가중치 $W$와 편향 $b$를 업데이트한다 ($W^{[l]} = W^{[l]} - \alpha dW^{[l]}$).

### **5. 에포크(Epoch)와 학습 속도 비교**
훈련 세트 전체를 한 번 도는 과정을 **1 Epoch**라고 한다.

**배치 경사 하강법:**  
1 에포크당 **1번**의 경사 하강(업데이트)만 일어난다.

**미니배치 경사 하강법:**  
1 에포크당 **5,000번**의 경사 하강(업데이트)이 일어난다.

데이터셋이 클 경우: 미니배치 경사 하강법이 훨씬 빠르게 수렴  
이것이 대규모 데이터 학습에 표준적으로 사용되는 이유이다.


## Understanding Mini-Batch Gradient Descent (C2W2L02)


### **1. 미니배치 경사 하강법의 비용 함수 그래프 특징**
![alt](/assets/img/c2w2.mini.png)

전체 훈련 세트를 사용하는 Batch Gradient Descent은 반복할 때마다 비용 함수 $J$가 반드시 감소해야 한다.  
반면, 미니배치 경사 하강법은 매 반복마다 서로 다른 미니배치($X^{\{t\}}, Y^{\{t\}}$)를 사용하기 때문에 그래프가 매번 감소하지 않고 Noise가 발생한다.  
특정 미니배치가 다른 미니배치보다 더 어렵거나 잘못 라벨링된 데이터를 포함할 수 있기 때문이지만 전체적인 흐름은 비용이 감소하는 방향으로 진행된다.

### **2. 미니배치 크기에 따른 두 가지 극단적인 경우**
![alt](/assets/img/c2w2.batch.png)

**크기 = $m$ (전체 데이터 크기):**  
배치 경사 하강법과 동일. 하나의 거대한 미니배치만 존재한다.


**크기 = 1:**  
이를 **Stochastic Gradient Descent, SGD**이라고 하며 각 샘플 하나하나가 각각의 미니배치가 된다.

### **3. 확률적 경사 하강법(SGD)과 배치 경사 하강법의 비교**
**배치 경사 하강법:**  
노이즈가 적고 최솟값을 향해 꾸준히 나아가지만 데이터가 클 경우 한 번의 Step를 밟는 데 너무 오랜 시간이 걸린다.

**확률적 경사 하강법(SGD):**  
매 샘플마다 업데이트를 하므로 빠르지만 방향이 잘못될 수도 있어 헤매면서 전역 최솟값 주변을 맴돌 뿐 영원히 수렴하지 않을 수 있다.  
큰 단점은 한 번에 하나의 샘플만 처리하므로 Vectorization를 통한 속도 향상의 이점을 잃게 된다.

### **4. 최적의 선택: 중간 크기의 미니배치**
실제로는 1과 $m$ 사이의 미니배치 크기를 선택하는 것이 가장 효율적이다. 이 방식은 다음과 같은 두 가지 장점을 가진다.

**벡터화 활용:**  
1,000개 정도의 샘플을 묶어 처리하면 벡터화의 이점을 살려 계산 속도를 높일 수 있다.

**빠른 학습:**  
전체 데이터를 다 볼 때까지 기다리지 않고도 파라미터를 업데이트할 수 있다.
적절한 미니배치 크기를 사용하면 최솟값 영역으로 더 일관되게 접근하며 수렴하지 않고 진동하는 문제는 Learning rate를 줄여서 해결할 수 있다.

### **5. 미니배치 크기 설정 가이드라인**
**작은 데이터셋 ($m < 2000$):**  
그냥 배치 경사 하강법을 사용하는 것이 좋다.

**큰 데이터셋:**  
일반적으로 **64에서 512 사이**의 값을 사용한다.

**2의 제곱수 사용:**  
컴퓨터 메모리 접근 효율을 위해 $2^6(64), 2^7(128), 2^8(256), 2^9(512)$와 같이 2의 제곱수를 사용하는 것이 코드를 더 빠르게 실행시킨다.

**메모리 확인:**  
선택한 미니배치 크기가 CPU나 GPU 메모리에 맞는지 확인해야 한다. 그렇지 않으면 성능이 급격히 저하될 수 있다.

### **6. 하이퍼파라미터 튜닝**
결국 미니배치 크기는 또 하나의 하이퍼파라미터이므로, 여러 2의 제곱수 값들을 시도해보며 비용 함수를 가장 효율적으로 줄이는 값을 찾아야 한다.


## Exponentially Weighted Averages (C2W2L03)

### **1. 지수가중평균(Exponentially Weighted Averages)의 필요성 도입**
경사 하강법보다 빠른 최적화 알고리즘들  
'지수가중이동평균'이라 불리는 **'지수가중평균'** :
최근 데이터에 더 큰 가중치를 주고, 오래된 데이터일수록 영향력을 지수적으로 감소시켜 계산하는 평균 방식
>작년 런던의 일별 기온 데이터. 이 데이터는 여름에 따뜻하고 겨울에 추운 경향이 있지만 매일의 데이터에는 노이즈가 섞여 있다. 이 데이터의 전반적인 흐름(지역 평균 또는 이동 평균)을 파악하기 위해 지수가중평균을 사용한다.

### **2. 공식의 정의와 의미**
지수가중평균을 구하는 공식
$$V_t = \beta V_{t-1} + (1-\beta)\theta_t$$

$V_t$: $t$ 시점의 지수가중평균 값  
$\theta_t$: $t$ 시점의 실제 데이터 (오늘의 기온)  
$\beta$: 가중치를 결정하는 하이퍼파라미터

> $\beta$가 0.9일 때 $V_t$는 대략 **$1/(1-\beta)$일 동안의 기온 평균** 과 같다.   
 $\beta=0.9$라면 $1/(1-0.9)=10$이므로 약 **10일간의 평균**을 나타내는 곡선이 그려진다.

### **3. 베타($\beta$) 값에 따른 변화 1: 값이 클 때**

![alt](/assets/img/c2w2.exp.png)


$\beta$를 1에 매우 가까운 값인 **0.98**로 설정하면, $1/(1-0.98)=50$이므로 약 **50일간의 기온 평균**을 구하게 된다 (초록색 선).  

**장점:**  
더 많은 날짜의 평균을 내므로 곡선이 훨씬 **부드러워진다**.  

**단점:**  
기온이 변할 때 적응하는 속도가 **느려진다**. 이전 값($V_{t-1}$)에 너무 큰 가중치를 주고 현재 값($\theta_t$)에는 작은 가중치를 주다 보니 실제 데이터의 변화를 따라가는 데 지연이 발생한다.

### **4. 베타($\beta$) 값에 따른 변화 2: 값이 작을 때**
반대로 $\beta$를 **0.5**로 설정하면, $1/(1-0.5)=2$이므로 약 **2일간의 평균**을 구하는 것과 같다 (노란색 선).  

**장점:**  
기온 변화에 **빠르게 적응**한다.

**단점:**  
평균을 내는 기간이 너무 짧아 **노이즈가 심하고** outliers에 민감하게 반응한다.

### **5. 하이퍼파라미터 튜닝**
결국 $\beta$는 학습 알고리즘의 **하이퍼파라미터**이다. 이 값을 조절함으로써 노이즈를 줄이면서도 변화에 적절히 반응하는 빨간색 선과 같은 최적의 값을 찾아야 한다.

---
**ai:**
**"운전할 때 얼마나 멀리 보느냐"** 와 비슷하다.

**$\beta$가 높음 (0.98):**  
아주 먼 과거의 길까지 다 고려해서 핸들을 꺾는 것이다. 승차감은 부드럽겠지만(부드러운 곡선), 급커브가 나왔을 때 반응이 늦어질 수 있다.

**$\beta$가 낮음 (0.5):**  
바로 코앞의 도로만 보고 핸들을 꺾는 것이다. 커브에 즉각 반응하지만, 도로의 작은 요철에도 핸들이 심하게 흔들릴 수 있다(노이즈).
우리는 이 둘 사이에서 가장 적절한 시야($\beta=0.9$ 등)를 찾아야 한다.

## Understanding Exponentially Weighted Averages (C2W2L04)
### **1. 지수가중평균 수식**
$$V_t = \beta V_{t-1} + (1-\beta)\theta_t$$
이 수식이 실제로 어떻게 작동하는지 이해하기 위해 $V_{100}$을 예로 들어 수식을 역순으로 푼다.

$V_{100} = 0.1\theta_{100} + 0.9V_{99}$
여기에 $V_{99}$ 등을 계속 대입하여 확장하면 $V_{100} = 0.1\theta_{100} + 0.1(0.9)\theta_{99} + 0.1(0.9)^2\theta_{98} + ...$ 와 같은 형태가 된다.  
지수가중평균은 각 시점의 데이터($\theta$)에 지수적으로 감소하는 가중치를 곱하여 모두 더한 값이다.

### **2. 평균 기간을 정하는 기준**
$\beta$ 값에 따라 '며칠 동안의 평균'인지 결정하는 수학적 원리.   
$(1-\epsilon)^{1/\epsilon} \approx 1/e$ (약 0.35)라는 수학적 극한을 활용한다. 


**$\beta=0.9$일 때:**  
가중치가 약 $1/3$로 줄어드는 데 10일이 걸리므로 약 **10일간의 평균**으로 본다.  
>오늘(1), 어제($0.9$), 그제($0.9^2=0.81$), ... 10일 전($0.9^{10} \approx 0.35$)

**$\beta=0.98$일 때:**  
가중치가 줄어드는 데 약 50일이 걸리므로 약 **50일간의 평균**이 된다.  
**$1/(1-\beta)$일 동안의 평균**이라고 생각할 수 있다.
> 오늘(1), 어제($0.98$), ... 50일 전($0.98^{50} \approx 0.36$)

### **3. 구현 알고리즘과 메모리 효율성**
간단하다  
$v$를 0으로 초기화한 뒤 반복문을 통해 매일 새로운 데이터($\theta_t$)가 들어올 때마다 $v := \beta v + (1-\beta)\theta_t$로 단 하나의 변수만 업데이트하면 된다.  
과거 10일이나 50일 치 데이터를 모두 배열에 저장하고 평균을 내는 방식보다 **실수 하나만 사용하기 때문에 메모리 사용량이 적고 계산 비용이 저렴**하다.


---
**ai:**
이 알고리즘의 효율성은 **"가계부 정리"** 에 비유할 수 있다.  
일반적인 평균 계산법: 지난 50일 치 영수증을 **모두 서랍에 보관했다가 매번 꺼내서 다시 계산**하는 방식   
지수가중평균: **머릿속에 현재의 대략적인 지출 흐름이라는 숫자 하나만 기억**해두고 오늘 쓴 돈을 반영해 그 숫자만 살짝 수정하는 것.  
영수증을 보관할 서랍(메모리)이 필요 없어 매우 가볍고 빠르다.

## Bias Correction of Exponentially Weighted Averages (C2W2L05)
### **1. 초기 단계의 Bias 문제 발생**  
![alt](/assets/img/c2w2.bias.png)

지수가중평균을 구현할 때 $v_0$를 0으로 초기화하면 학습 초기 단계에서 계산된 값이 실제 데이터보다 현저히 낮게 나오는 현상(보라색 곡선)이 발생한다. 
> $\beta=0.98$이고 첫날($t=1$)의 온도가 40도라면 $v_1 = 0.98 \times 0 + 0.02 \times 40 = 8$이 되어 실제 값인 40도를 전혀 반영하지 못하게 된다. 

### **2. 편향 보정(Bias Correction) 공식 도입**  
이러한 초기 추정 오차를 해결하고 더 정확한 평균(초록색 곡선)을 얻기 위해 **편향 보정**을 사용한다. 단순히 $v_t$를 사용하는 대신 다음 공식을 사용한다.
$$ \frac{v_t}{1 - \beta^t} $$
여기서 $t$는 현재 시점이다. 
> $t=2, \beta=0.98$일 때 분모는 $1 - (0.98)^2 = 0.0396$이 되며, 작게 계산된 $v_t$ 값을 이 작은 수로 나누어줌으로써 스케일을 정상 범위로 보정해준다.

### **3. 시간이 지남에 따른 효과 감소**  
시간 $t$가 커질수록 $\beta^t$ 값은 0에 가까워지므로 분모인 $(1 - \beta^t)$는 1에 수렴하게된다. 데이터가 충분히 쌓인 후반부에는 편향 보정의 영향력이 사라져 보정을 한 곡선과 하지 않은 곡선이 거의 겹치게 된다.  
편향 보정은 주로 초기 단계(warm-up phase)의 정확도를 높인다.

### **4. 머신러닝에서의 실제 활용**
실제 머신러닝 구현에서는 초기 단계의 부정확함을 그냥 기다려서 지나보내는 방식(warm-up)을 사용하여 편향 보정을 생략하는 경우도 많다. 하지만 초기 학습 단계부터 정확한 추정값이 필요한 상황이라면 편향 보정을 구현하는 것이 유용하다.





## Gradient Descent With Momentum (C2W2L06)
### **1. 기본 경사 하강법의 문제점: 진동(Oscillation)**
일반적인 경사 하강법이나 미니배치 경사 하강법을 타원형의 등고선(최적화 문제)에 적용하면 비효율적인 움직임이 발생한다.

![alt](/assets/img/c2w2.grad.png)

최솟값(중심)을 향해 수평 방향으로는 천천히 나아가지만 수직 방향으로는 위아래로 심하게 진동하며 움직이다.

**단점:**  
이 진동 때문에 더 큰 Learning rate을 사용할 수 없다. 학습률을 높이면 진동이 너무 커져서 경로를 이탈할 위험이 있기 때문이다.

### **2. Momentum의 핵심 아이디어**
우리의 목표는 **수직 방향(진동)은 줄이고, 수평 방향(학습)은 빠르게** 만드는 것이다. 이를 위해 Gradient에 대한 **지수가중평균(Exponentially Weighted Averages)**을 계산하여 가중치를 업데이트한다.

현재 미니배치의 도함수($dW, db$)를 계산한 뒤 이동 평균 $v_{dW}, v_{db}$를 구한다.
    $$v_{dW} = \beta v_{dW} + (1-\beta)dW$$
    $$v_{db} = \beta v_{db} + (1-\beta)db$$

**업데이트:**  
기존의 $dW, db$ 대신 $v_{dW}, v_{db}$를 사용하여 파라미터를 업데이트한다.
    $$W = W - \alpha v_{dW}, \quad b = b - \alpha v_{db}$$
    $\alpha$: 학습률

### **3. 모멘텀의 효과**
이 방식을 사용하면 지난 몇 번의 반복 동안 계산된 경사들의 평균을 구한다.  

**수직 방향:**  
양수와 음수가 번갈아 나오므로 평균을 내면 서로 상쇄되어 0에 가까워진다(진동 감소).

**수평 방향:**  
모든 경사가 최솟값을 향해 같은 방향을 가리키므로 평균값이 크고 일정하게 유지된다(속도 증가).  

진동은 줄어들고 최솟값을 향해 더 직선에 가까운 경로로 빠르게 이동하게 된다.

### **4. 물리적 직관**

이 알고리즘은 물리적인 현상에 비유할 수 있다.

**공:**  
파라미터가 밥그릇(비용 함수 그래프) 안을 굴러 내려간다.

**Gradient:**  
공에 가해지는 **가속도(Acceleration)** 역할을 한다.

**모멘텀 변수($v_{dW}, v_{db}$):**  
공의 **속도(Velocity)** 역할을 한다.

**베타($\beta$):**  
**마찰(Friction)** 역할을 하여 공이 무한정 빨라지는 것을 막는다.
모멘텀 알고리즘은 매 단계마다 멈췄다 다시 출발하는 것이 아니라 가속도를 받아 속도가 붙은 공처럼 더 빠르게 최솟값으로 굴러가게 한다.

### **5. 구현 세부 사항 및 하이퍼파라미터**
**$\beta$ 설정:**  
가장 일반적이고 견고한 값은 **0.9**이다. 이는 대략 지난 10번의 반복(10일간의 평균)을 고려하는 것과 같다.

**Bias Correction:**  
보통 모멘텀 구현에서는 초기 편향 보정 단계를 **생략**한다. 10번 정도 반복하면 이동 평균이 충분히 안정화되기 때문이다.

**초기화:**  
$v_{dW}$와 $v_{db}$는 0으로 초기화한다.

### **6. 다른 버전의 공식**
일부 논문이나 프레임워크에서는 $(1-\beta)$ 항을 생략한 공식을 사용하기도 한다 ($v_{dW} = \beta v_{dW} + dW$).  
이 경우 $v_{dW}$가 $1/(1-\beta)$만큼 스케일링되므로 학습률 $\alpha$를 그에 맞춰 조정해야 한다.  
강의에서는 $(1-\beta)$가 포함된 원래 공식이 하이퍼파라미터 튜닝 시 $\alpha$에 덜 영향을 주기 때문에 더 선호한다고 언급한다.




## **RMSProp (C2W2L07)** 

### **1. RMSProp의 도입 목적과 직관**
Momentum과 마찬가지로 **RMSProp(Root Mean Square Prop)** 역시 경사 하강법의 속도를 높이는 알고리즘이다.

![alt](/assets/img/c2w2.rms.png)

경사 하강법을 시각화했을 때, 최적값으로 향하는 수평 방향($w$)으로는 빠르게 이동하고 싶지만 불필요한 수직 방향($b$)의 진동이 커서 학습 속도가 느리다.

**목표:**  
수직 방향(b)의 학습 속도는 늦추고(진동 억제), 수평 방향(w)의 학습 속도는 빠르게 유지

### **2. RMSProp 알고리즘의 공식**
RMSProp은 매 반복($t$)마다 도함수의 **제곱**에 대한 지수가중평균을 계산한다.

새로운 변수 $S_{dw}$와 $S_{db}$를 사용.  
    $S_{dw} = \beta S_{dw} + (1-\beta) dw^2$  
    $S_{db} = \beta S_{db} + (1-\beta) db^2$
    (여기서 제곱은 요소별 제곱)

**업데이트:**  
매개변수 업데이트 시 도함수를 $S$값의 **제곱근**으로 나눈다.  
    $w := w - \alpha \frac{dw}{\sqrt{S_{dw}}}$  
    $b := b - \alpha \frac{db}{\sqrt{S_{db}}}$

### **3. 진동을 줄이는 방법**

**수직 방향($b$):**  
경사가 가파르므로 도함수 $db$가 매우 크다. 따라서 $db^2$과 $S_{db}$도 커진다. 업데이트할 때 $db$를 큰 수($\sqrt{S_{db}}$)로 나누게 되므로 결과적으로 업데이트 폭(진동)이 준다.

**수평 방향($w$):**  
경사가 완만하여 $dw$가 작다. 따라서 $S_{dw}$도 작아지며 작은 수로 나누기 때문에 업데이트 속도가 유지되거나 가속된다.

수직 방향으로 발산하지 않으면서 더 **큰 학습률($\alpha$)** 을 사용할 수 있게 되어 학습 속도가 빨라진다

### **4. 명칭의 유래와 표기법 주의사항**
도함수를 제곱(Square)하여 Mean을 내고, 업데이트 시 루트를 씌우기 때문에 **RMS(Root Mean Square)Prop**이라고 부른다.
  
**하이퍼파라미터 $\beta$:**  
모멘텀 알고리즘과 결합하여 사용할 때 혼동을 피하기 위해 RMSProp의 $\beta$는 주로 **$\beta_2$** 로 표기한다.

### **5. 구현 시의 팁**
**수학적 안정성:**  
구현할 때는 분모($\sqrt{S}$)가 0이 되어 계산이 폭발하는 것을 막기 위해 아주 작은 값인 **$\epsilon$** 을 분모에 더한다.





## Adam Optimization Algorithm (C2W2L08)
### **1. Adam 알고리즘의 배경과 신뢰성**
딥러닝 역사에서 많은 최적화 알고리즘이 제안되었지만 특정 문제에만 잘 작동하고 일반화되지 않는 경우가 많았다.  
그러나 **Adam**과 **RMSprop**은 다양한 딥러닝 아키텍처 전반에서 우수한 성능을 보여주는 드문 알고리즘으로 자리 잡았다.  
**Adam(Adaptive Moment Estimation)** = **모멘텀(Momentum)** + **RMSprop**

### **2. 초기화 및 기본 계산 단계**
Adam을 구현하기 위해 먼저 $v_{dw}, s_{dw}$ 등 관련 변수들을 모두 0으로 초기화한다. 이후 iteration $t$에서 다음과 같은 단계.

**기울기 계산:**  
현재 미니배치를 사용하여 도함수($dw, db$)를 계산한다.

**Momentum 단계:**  
기울기의 지수가중평균을 계산한다. 하이퍼파라미터: $\beta_1$  
이는 모멘텀 알고리즘의 방식과 동일하다 ($v_{dw} = \beta_1 v_{dw} + (1-\beta_1)dw$).
> 관성을 이용해 차가 목적지 방향으로 꾸준히 속도를 내게 도와준다 (내비게이션 및 엔진).


**RMSprop 단계:**  
기울기 제곱의 지수가중평균을 계산한다. 하이퍼파라미터: $\beta_2$  
RMSprop 방식과 동일하다 ($s_{dw} = \beta_2 s_{dw} + (1-\beta_2)dw^2$).
>도로가 울퉁불퉁할 때(경사가 급격히 변할 때) 속도를 조절하여 차가 튀지 않게 잡아준다 (충격 흡수 장치).

### **3. Bias Correction**
초기화 단계에서 발생할 수 있는 오차를 줄이기 위해 계산된 $v$와 $s$에 편향 보정을 적용한다. 학습 초기($t$가 작을 때)에 값이 0으로 편향되는 것을 막는다.

$v_{corrected} = v / (1-\beta_1^t)$  
$s_{corrected} = s / (1-\beta_2^t)$

### **4. 매개변수 업데이트**
보정된 값들을 사용하여 최종적으로 가중치를 업데이트한다.
$$W = W - \alpha \frac{v_{corrected}}{\sqrt{s_{corrected}} + \epsilon}$$

모멘텀의 효과(속도 및 방향 유지)와 RMSprop의 효과(진동 감쇠)를 동시에 적용

### **5. 하이퍼파라미터 선택 가이드**
Adam 알고리즘에는 여러 하이퍼파라미터가 있지만 일반적으로 추천되는 값들이 존재한다.

**$\alpha$ (학습률):**  
가장 중요하며, 사용자가 직접 튜닝해서 찾아야 한다.

**$\beta_1$:**  
모멘텀 항(1차 모멘트)으로 기본값 **0.9**를 주로 사용한다.

**$\beta_2$:**  
RMSprop 항(2차 모멘트)으로 논문 저자는 **0.999**를 추천한다.

**$\epsilon$:**  
분모가 0이 되는 것을 방지하는 작은 수로 **$10^{-8}$**을 추천하며 굳이 튜닝할 필요는 없다.




## Learning Rate Decay (C2W2L09)

### **1. Learning Rate Decay의 필요성**
Mini-batch Gradient Descent을 사용할 때 64나 128과 같은 작은 미니배치를 쓰면 계산 과정에 약간의 노이즈가 발생한다.  
고정된 학습률($\alpha$)을 계속 사용하면 최적화 과정이 최솟값을 향해 가긴 하지만 정확히 수렴하지 못하고 최솟값 주변을 계속 진동한다.  
학습률 감쇠를 적용하면 초기에는 큰 학습률로 빠르게 학습을 진행하고 학습이 진행될수록 학습률을 줄여서 최솟값 근처의 좁은 영역에서 진동하는 폭을 줄여 더 정밀하게 수렴할 수 있다.

### **2. 기본 구현 방법과 수식**
에포크: 전체 훈련 데이터를 한 번 훑는 것

가장 기본적인 감쇠 공식:
$$ \alpha = \frac{1}{1 + \text{decay\_rate} \times \text{epoch\_num}} \alpha_0 $$
decay_rate(감쇠율): 튜닝해야 할 하이퍼파라미터  
epoch_num: 현재 에포크 횟수

에포크가 늘어날수록 학습률이 점차 감소한다.

### **3. 다양한 감쇠 방법들**
**지수적 감쇠(Exponential Decay):**  
$\alpha = 0.95^{\text{epoch\_num}} \times \alpha_0$ 와 같이 1보다 작은 수를 거듭제곱하여 학습률을 기하급수적으로 빠르게 감소시킨다.

**제곱근 감쇠:**  
$\frac{k}{\sqrt{\text{epoch\_num}}} \times \alpha_0$ 또는 미니배치 번호 $t$를 사용하여 $\frac{k}{\sqrt{t}} \times \alpha_0$와 같은 방식을 사용한다.

**Discrete Staircase:**  
특정 시간이 지나거나 몇 에포크마다 학습률을 절반으로 뚝 떨어뜨리는 방식이다.

### **4. 수동 감쇠(Manual Decay)와 중요도**
모델 훈련에 며칠이 걸리는 경우 개발자가 훈련 과정을 지켜보다가 학습 속도가 느려지거나 정체될 때 직접 수동으로 학습률을 낮추는 방법. 이는 훈련하는 모델의 수가 적을 때 유효한 방법이다.  
학습률 감쇠가 훈련 속도를 높이고 성능에 도움을 주지만 다른 하이퍼파라미터 튜닝(특히 초기 학습률 $\alpha$ 자체의 설정)에 비해 우선순위는 낮다.


