---
layout: post
title: "[CS231n] 11. Detection and Segmentation"
date: 2026-02-24 09:50
categories: MyStudy CS231n
tags: cv CS231n
math: true
---

강의 주소: <br>
[CS231n Lecture 11. Detection and Segmentation](https://www.youtube.com/watch?v=nDPWywWRIRo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=11)

자료: <br>
[깃허브 강의 자료](https://github.com/visionNoob/CS231N_17_KOR_SUB?tab=readme-ov-file)




## 1. 지난 강의 복습

**순환 신경망(RNN):**  
가변 길이의 시퀀스를 처리하여 언어 모델링, 셰익스피어나 C 코드 생성, 이미지 캡셔닝(CNN+RNN 결합) 등에 활용되는 것을 배웠다.

**LSTM:**  
Vanilla RNN의 Gradient flow을 개선하여 긴 시퀀스에서도 의존성을 잘 포착하도록 설계된 구조에 대해 다루었다.


전체 이미지에 단일 레이블을 부여하는 Image Classification에서 벗어나 픽셀 단위로 공간적 위치를 파악하는 다양한 컴퓨터 비전 작업들로 주제를 확장한다.

## 2. Semantic Segmentation
입력 이미지의 **모든 픽셀마다 카테고리를 분류**하는 작업이다.

**특징 및 한계:**  
픽셀 단위로 잔디, 하늘, 고양이 등을 구분하지만 **개별 객체를 구분하지는 않는다**.
>두 마리의 소가 붙어 있어도 각각의 소를 구별하지 않고 하나의 거대한 '소 픽셀 덩어리'로만 인식한다.

**접근법 1: Sliding Window**
    
이미지를 작은 패치로 쪼개어 각 패치의 중심 픽셀 카테고리를 분류하는 방식이다.
    
**문제점:**  
    모든 픽셀에 대해 별도의 패치를 만들어 각각 CNN을 통과시켜야 하므로 연산 비용이 엄청나게 높고 겹치는 패치 간에 공유할 수 있는 연산을 중복 수행하기 때문에 **절대 사용해서는 안 되는 매우 비효율적인 방법**이다.

**접근법 2: Fully Convolutional Network**
    
패치를 나누지 않고 전체 이미지를 3x3 합성곱 레이어로만 쌓아 통과시킨다.
    
출력 텐서의 크기를 입력과 동일하게(C x H x W, C는 카테고리 수) 유지하며 모든 픽셀에 대해 독립적으로 Cross-entropy loss를 계산해 학습한다.
    
**문제점:**  
    입력 이미지의 원본 해상도를 전체 네트워크 깊이 내내 유지하려면 막대한 연산량과 메모리가 필요하다.

**접근법 3: Downsampling & Upsampling**
    
앞단에서는 Max pooling이나 Strided convolution을 통해 해상도를 줄이고(Downsampling) 뒷단에서는 다시 원래 크기로 늘리는(Upsampling) 병목 형태의 아키텍처를 사용한다. 이렇게 하면 깊은 네트워크를 훨씬 효율적으로 구성할 수 있다.

## 3. Upsampling 기법들
공간 해상도를 다시 키우는 레이어들의 종류이다.

**Nearest Neighbor Unpooling:**  
같은 값을 주변 픽셀로 단순히 복제하여 채운다.

**Bed of Nails Unpooling:**  
수용 영역의 한쪽 구석에만 값을 넣고 나머지는 0으로 채우는 방식이다.

**Max Unpooling:**  
다운샘플링 단계에서 Max pooling을 할 때 최대값이 있던 위치를 기억해 두었다가 업샘플링 시 그 위치에 정확히 값을 넣고 나머지는 0으로 채운다. 이는 풀링 과정에서 손실된 공간적 미세 정보를 복원하여 시맨틱 세그멘테이션의 정밀한 픽셀 경계를 찾는 데 도움을 준다.

**Transpose Convolution (매우 중요)**
    
앞선 방법들이 고정된 규칙을 쓰는 반면 전치 합성곱은 **학습 가능한 가중치**를 통해 업샘플링을 수행한다.
    
**작동 방식:**  
    입력 피처 맵의 스칼라 값 하나에 필터의 가중치들을 곱한 뒤, 그 결과를 출력 영역에 배치한다.  
    


## 4. Classification + Localization
이미지 내에 **정확히 하나의 대상 객체**가 있다고 가정할 때, 카테고리를 분류하고 바운딩 박스를 찾는 작업이다.

**아키텍처:**  
입력 이미지가 CNN을 통과하여 최종 벡터가 추출되면 두 갈래의 Fully Connected Layer으로 나뉜다.
    
하나는 클래스 점수를 예측(Softmax loss 사용).
    
다른 하나는 경계 상자의 좌표 4개(x, y, 너비, 높이)를 예측.

**Multitask Loss:**  
이 두 가지 손실을 Hyperparameter를 두어 합산한 뒤 동시에 역전파를 수행한다. 단위가 다른 두 손실을 합치기 때문에 가중치 설정이 매우 까다로우며 손실 값 자체가 아닌 실제 모델 성능 지표를 기준으로 설정해야 한다. Transfer learning을 사용할 때 전체 시스템을 동시에 미세 조정하는 것이 성능이 제일 좋다.


## 5. Object Detection
이미지 안에 **몇 개의 객체가 있는지 미리 알 수 없는 상황**에서 모든 객체의 위치와 종류를 찾아야 하는 훨씬 어려운 과제이다.

**접근법 1: 슬라이딩 윈도우**
    
다양한 크기, 비율, 위치의 작물을 무작위로 추출해 CNN에 넣고 분류한다.
    
경우의 수가 수만 가지가 넘기 때문에 연산이 불가능하여 실제로는 사용하지 않는다.

**접근법 2: Region Proposals**
    
전통적인 이미지 처리 기법을 사용해 객체가 있을 만한 Blob 형태의 영역 약 2,000개를 빠르게 뽑아낸다. 비록 노이즈가 많지만 실제 객체를 포함할 확률이 매우 높다.

### (1) R-CNN

지역 제안으로 찾은 2,000개의 ROI(Region of Interest)를 모두 동일한 크기로 Warping한 후 각각을 CNN에 통과시킨다. 이후 SVM으로 클래스를 분류하고 별도의 회귀 모델로 경계 상자의 오차를 보정한다.

**단점:**  
2,000개의 패치를 매번 개별적으로 CNN에 넣어야 하므로 연산이 매우 느리고 특징을 하드디스크에 저장해야 해서 수백 GB의 용량을 차지한다.

### (2) Fast R-CNN

R-CNN의 속도 문제를 해결했다. 이미지를 처음부터 쪼개지 않고 **전체 이미지를 CNN에 단 한 번만 통과**시켜 전체 고해상도 피처 맵을 만든다.

Selective Search로 찾은 ROI 좌표를 이 피처 맵 위에 Project한 뒤 **ROI Pooling**이라는 기법을 써서 각 영역의 피처를 추출한다.

이를 통해 중복 연산을 제거하여 학습 속도를 10배 이상 높였고 테스트 속도도 1초 미만으로 단축시켰다.

**단점:**  
모델 연산은 매우 빨라졌으나 여전히 외부 알고리즘으로 지역 제안을 만드는 데 걸리는 2초가 가장 큰 병목이 되었다.

### (3) Faster R-CNN

외부 알고리즘을 버리고 네트워크 내부에서 **지역 제안 자체를 예측하는 RPN(Region Proposal Network)**을 추가했다.

전체 프로세스: 이미지 -> CNN 전체 피처 맵 -> **RPN** -> 추출된 제안 영역들에 대해 ROI Pooling -> 분류 및 경계 상자 보정.

총 4가지 손실(RPN의 객체 여부 이진 분류 및 박스 회귀, 최종 분류 및 최종 박스 회귀)을 동시에 최소화하며 End-to-End로 학습된다. 외부 병목이 사라져 속도가 극적으로 빨라졌다.

## 6. Single Shot Detectors: YOLO, SSD
R-CNN 계열처럼 지역을 먼저 제안하고 처리하는 2단계 방식과 달리 전방향(Feed-forward) 한 번에 처리를 끝내는 방식이다.

**작동 원리:**  
이미지를 그리드로 나누고 각 그리드 셀마다 미리 정해둔 다양한 크기/비율의 Base bounding boxes를 설정한다. 그리고 단 한 번의 CNN 연산으로 각 기본 박스 위치에 대한 오프셋 좌표와 클래스 신뢰도 점수를 모두 예측하는 3차원 텐서를 출력한다.

이 방식은 지역별 후처리가 필요 없기 때문에 Faster R-CNN보다 속도가 훨씬 빠르지만 일반적으로 정확도는 조금 떨어지는 경향이 있다.


## 7. 인스턴스 세그멘테이션과 Mask R-CNN

**정의:**  
시맨틱 세그멘테이션과 객체 탐지의 하이브리드 형태로, 이미지 안의 개별 객체를 식별함과 동시에 각 객체에 속하는 **정확한 픽셀 Mask**까지 예측하는 궁극의 과제이다.

**Mask R-CNN (최신 연구):**  
Faster R-CNN 구조를 그대로 가져오되, ROI Pooling 후단에 기존의 [분류 + 박스 회귀] 브랜치 외에 **[픽셀 분할(Mask)] 브랜치를 하나 더 추가**한 아키텍처이다.

각 ROI 안에 작은 시맨틱 세그멘테이션 네트워크가 하나씩 들어가는 형태이다.

**성능 확장성:**  
이 아키텍처에 브랜치를 하나 더 추가하면 인체 포즈 추정까지 동시에 수행할 수 있다. 붐비는 사람들의 픽셀 마스크와 골격을 단 한 번의 포워드 패스로 놀라울 정도로 정교하게 찾아낸다.

**데이터 요구량:**  
이 엄청난 성능의 이면에는 Microsoft COCO 데이터셋이라는 막대한 양의 지도 학습 데이터가 필요하다는 점을 명심해야 한다. 향후 더 적은 데이터로 이 정도 성능을 내는 것이 주요 연구 과제이다.

이미지 분류를 위해 구축했던 CNN 핵심 기술들이 세그멘테이션과 탐지라는 새로운 컴퓨터 비전 과제에 어떻게 적용되는지 빠르게 살펴보았다. 
