---
layout: post
title: "[CS231n] 1. Introduction to Convolutional Neural Networks for Visual Recognition"
date: 2025-12-23 09:50
categories: MyStudy CS231n
tags: cv CS231n
math: true
---

이번 방학에 공부하려고 계획 중이다. 영상 링크는 다음과 같다. <br>
강의 주소: <br>
[CS231n 유튜브 링크](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk)

추가로 참고한 자료는 다음이다. <br>
자료: <br>
[깃허브 강의 자료](https://github.com/visionNoob/CS231N_17_KOR_SUB?tab=readme-ov-file)



그럼 시작해보도록 하겠다

<br>
<br>
<br>


## Computer Vision
전 세계 센서에서 쏟아지는 방대한 시각 데이터를 이해하기 위한 알고리즘 분야다. 
인터넷 상의 시각 데이터가 정확히 무엇으로 구성하는지 이해하고 파악하는 것은 어렵다

물리학의 **암흑 물질(Dark Matter)** 처럼 시각 데이터는 인터넷 트래픽의 약 80%를 차지하지만 알고리즘이 그 내용을 들여다보고 이해하기 어렵다. 유튜브에는 매초 5시간 분량의 영상이 업로드되므로 이를 자동으로 분류하고 이해하는 기술이 필요하다

## Interdisciplinary Fields
- 물리학: 광학, 이미지 형성 과정 이해.
- 생물학/심리학: 동물의 뇌가 시각 정보를 처리하는 방식 이해.
- 컴퓨터 과학/수학/공학: 실제 비전 알고리즘을 구현하고 시스템을 구축.



## History of Vision

인간의 대뇌 피질 뉴런의 약 50%가 시각 정보를 처리한다. <br>
시각 처리가 시각 세계의 단순한 구조, 가장자리에서 시작된다. 신호가 이동함에 따라 복잡성을 축적해 나간다.

1959년 Hubel과 Wiesel은 고양이의 시각 피질 연구를 통해 시각 처리가 가장자리(edge)와 같은 단순한 자극에 반응하는 세포에서 시작해 복잡한 정보를 처리하는 방향으로 계층적으로 이루어짐을 발견했다

## A Block World

세상을 단순한 블록들의 조합으로 가정하는 사고 실험적 세계관이다

1960년대 초 Larry Roberts가 발표한 컴퓨터 비전 분야의 초기 논문 중 하나이다. 복잡한 사물을 단순한 기하학적 모양으로 인식하고 재구성하려는 시도였다

## The Summer Vision Project

MIT에서 진행된 초기 컴퓨터 비전 연구 프로젝트로 카메라 입력으로부터 물체를 인식하는 것을 목표로 했다.

여름 방학 동안 시각 시스템의 대부분을 구현하려는 야심 찬 목표로 시작되었다. 하지만 시각 인식은 매우 어려운 문제임이 드러났고 이 하나의 프로젝트가 이후 50년 넘게 이어지는 거대한 연구 분야의 시발점이 되었다

## David Marr

시각을 계산 문제로 정의하고 단순한 경계에서 복잡한 3D 모델로 나아가는 계층적 처리 단계를 제안했다.
시각 연구의 방향을 바꿨지만 실제 신경 구현과는 차이가 크다는 비판도 있다.

컴퓨터 비전 연구의 방향을 제시하며 수십 년간 분야를 지배했다. 그는 이미지를 최종적인 3D 표현으로 변환하기 위해 몇 가지 처리 단계를 거쳐야 한다고 주장했다

## Primal Sketch
입력 이미지에서 3D로 가기 위해 과정을 거쳐야한다.

David Marr가 제안한 첫 번째 단계로 이미지의 가장자리(edges), 선, 곡선 등 단순한 구조를 표현합니다. 이는 신경과학의 발견, Hubel & Wiesel에서 영감을 받은 것이다. 이후 표면과 깊이 정보를 다루는 2.5D Sketch 단계를 거쳐 최종적인 3D 모델로 나아간다

## Regresentation
객체를 어떻게 표현할 것인가에 대한 고민이 많았다. 당시 스탠포드와 SRI 연구진은 **'Generalized Cylinder'** 나 'Pictorial Structure' 같은 개념을 제안했다. 이는 모든 복잡한 객체를 단순한 기하학적 모양의 조합이나 스프링으로 연결된 부품들의 집합으로 단순화하여 표현하고 인식하려는 시도였다

## Image Segmentation
객체 인식을 하려면 분리부터 해야하지 않을까 하는 생각에서 출발했다


## Face Detection
Statistical Machine Learning이 도입되면서 큰 진전을 이뤘다. 2001년 Paul Viola와 Michael Jones가 발표한 AdaBoost 알고리즘 기반의 얼굴 인식은 당시 느린 컴퓨터에서도 Real-time 처리가 가능할 정도로 효율적이었다. 이 기술은 학문적 성과에 그치지 않고 불과 5년 뒤인 2006년 후지필름 디지털카메라에 탑재되며 빠르게 상용화되었다.


## FeatureBased Object Recongnition
특징 기반 객체 인식.
전체를 정확하게 다른 물체에 일치 시키는 것은 어렵다. 변형이 일어날 수 있기 때문이다. 하지만 특징은 변하지 않는다. 핵심 특징을 식별하고 유사한 패턴에 연결하는 것이다. 카메라 각도, 조명, 가림 등이 있어도 변하지 않는 고유한 특징점을 찾아 매칭하는 방식이다

공간 피라미드 매칭. 여러 부분에서 특징을 추출해서 서포트벡터 머신 알고리즘에 적용한다. 

## Visual Object Recognition
객체 인식의 발전을 측정하기 위해 PASCAL VOC와 같은 벤치마크 데이터셋이 등장했다. 초기에는 20개 카테고리에 불과했지만 이를 통해 연도별 알고리즘의 성능 향상을 정량적으로 확인할 수 있게 되었다

## ImageNet
컴퓨터 비전 연구, 시각적 객체 인식  개발을 위해 설계된 대규모 라벨이 지정된 이미지 데이터베이스.
오버피팅 문제를 극복하기 위해 설계된 1500만장 이상의 거대 데이터셋으로 객체 인식 기술을 발전시키는 계기가 되었다. 

## ImageNet Results
ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 챌린지 결과 초기 2년 동안은 오류율이 25%대에 머물렀다. 하지만 CNN을 사용한 AlexNet이 등장하면서 오류율이 16%대로  하락했다

## Image Classification
이미지 한장을 보고 몇개의 고정된 카테고리 안에서 정답 하나를 고른다. 한정적이거나 인위적으로 보일 수도 있지만 일반적이다. 객체 검출, 캡셔닝 등 모든 시각 문제의 기초이다. 
>이미지 캡셔닝: 컴퓨터 비전과 자연어 처리를 결합해 주어진 이미지의 내용을 분석하고 그에 대한 설명을 사람이 이해할 수 있는 문장으로 생성하는 기술

## Other Visual Recognition Problem

객체 탐지(Object Detection): 이미지를 분류하는 것을 넘어 이미지 내의 객체마다 '강아지', '고양이'와 같이 Bounding Box를 그려 위치까지 찾아내는 것. 

이미지 캡셔닝(Image Captioning): 컴퓨터 비전과 자연어 처리를 결합해 주어진 이미지의 내용을 분석하고 그에 대한 설명을 사람이 이해할 수 있는 문장으로 생성하는 기술.


## Convolutional Neural Networks
2012년 AlexNet의 등장을 기점으로 이미지 인식 오류율을 크게 낮추며 현대 인공지능의 주류를 이룬다. <br>
갑자기 나타난 것이 아닌 오래 존재해왔다.

## Open Challenges

## Visual Genome
단순히 객체에 박스를 치는 것을 넘어 객체 간의 Relationships, Attributes, Actions 등을 포함한 거대한 Semantic Graph로 이미지를 이해하려는 시도다

## The Holy Grail
컴퓨터 비전의 최종 목표는 사진 속 상황의 맥락, 유머, 인간관계까지 파악하는 것이다.

