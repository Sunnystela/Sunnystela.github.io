---
layout: post
title: "[CS231n] 5. Convolutional Neural Networks"
date: 2026-01-18 09:50
categories: MyStudy CS231n
tags: cv CS231n
math: true
---

강의 주소: <br>
[CS231n Lecture Lecture 5. Convolutional Neural Networks](https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=5)

자료: <br>
[깃허브 강의 자료](https://github.com/visionNoob/CS231N_17_KOR_SUB?tab=readme-ov-file)



### 1.  복습
이전까지 선형 레이어(Linear Layer)를 쌓고 그 사이에 비선형성(Non-linearity)을 넣어 신경망을 구성하는 법을 배웠다. 

### 2. 신경망과 CNN의 역사 (History)
**1957년 (Frank Rosenblatt):**  
'Mark I Perceptron'이라는 기계를 개발했다. $W \times X + b$ 형태의 스코어 함수 개념이 있었으나 당시에는 역전파(Backpropagation)가 없었고 가중치를 목표 방향으로 단순히 조정하는 업데이트 규칙만 존재했다.

**1960년 (Widrow & Hoff):**  
Adaline/Madaline을 개발하여 최초로 다층 퍼셉트론(Multi-layer Perceptron) 레이어를 쌓는 시도를 했으나 여전히 체계적인 학습 방법은 없었다.

**1986년 (Rumelhart 등):**  
비로소 **역전파(Backpropagation)**가 처음으로 소개되며 신경망을 학습시키는 원칙적인 방법이 정립되었다.

**2006년 (Hinton 등):**  
신경망의 암흑기를 지나 딥러닝이 다시 주목받기 시작했다. 초기화(Initialization)를 신중하게 수행한 뒤 역전파로 미세 조정(Fine-tuning)을 하면 깊은 신경망을 학습시킬 수 있음을 보였다.

**2012년:**
음성 인식 분야에서 Hinton 연구실이 큰 성과를 냈다.  
    **AlexNet:**  
    Alex Krizhevsky가 최초의 현대적인 CNN 아키텍처를 소개하며 ImageNet 분류 대회에서 오차율을 획기적으로 낮추는 기념비적인 성과를 거뒀다.

### 3. 생물학적 영감 (Biological Inspiration)
CNN의 아이디어는 뇌의 시각 피질 연구에서 시작되었다.
**1959년 (Hubel & Wiesel):**  
고양이의 뇌에 전극을 꽂아 시각적 자극에 대한 반응을 실험했다.  
    **위상학적 매핑(Topographical Mapping):**  
    시각 피질의 세포들이 시야의 특정 영역과 매핑되어 있음을 발견했다.  
    **계층적 구조(Hierarchical Organization):**  
    초기 단계의 세포(Simple cells)는 빛의 방향(Oriented edges)에 반응하고 그다음 단계(Complex cells)는 움직임 등에 반응하며 점차 복잡한 특징(Hypercomplex cells)을 인식한다는 것을 발견했다.

**1980년 (Fukushima):**  
이 아이디어를 바탕으로 'Neocognitron'이라는 아키텍처를 제안했다. 단순 세포와 복잡 세포를 교대로 배치하는 구조를 가졌다.

**1998년 (Yann LeCun):**  
CNN에 역전파를 적용하여 우편번호(Zip code)와 같은 문서 인식에 성공했다.

**2012년 (AlexNet):**  
1998년의 구조와 비슷하지만 ImageNet이라는 거대한 데이터와 GPU의 병렬 처리 능력을 활용하여 규모를 키운 현대적인 CNN이 탄생했다.

### 4. CNN의 다양한 응용 사례
현재 CNN은 매우 광범위하게 사용되고 있다.

**기본 기능:**  
이미지 검색 객체 탐지(Detection 박스 그리기) 분할(Segmentation 픽셀 단위 분류) 등에 사용되며 자율 주행 자동차 등에서 핵심적인 역할을 합니다.

**그 외:**  
안면 인식 비디오 분류 포즈 인식(관절 찾기) 게임 플레이(강화 학습) 의료 영상 분석 은하 분류 거리 표지판 인식 항공 지도 분석 이미지 캡셔닝(이미지 설명 생성) 예술 작품 생성(Deep Dream Style Transfer) 등 수많은 분야에 적용된다.

### 5. CNN의 동작 원리: 합성곱 레이어 (Convolution Layer)
**완전 연결 레이어(Fully Connected Layer)와의 차이:**  
    기존 FC 레이어는 32x32x3 이미지를 3072차원의 긴 벡터로 펼쳐서 처리했다.
    **Convolution Layer**는 이미지의 **공간적 구조(Spatial Structure)**를 유지합니다. 32x32x3 형태를 그대로 입력으로 받는다.

**필터(Filter):**  
    필터는 공간적으로는 작다(예: 5x5). 하지만 **깊이(Depth)는 입력 볼륨의 전체 깊이와 항상 같다**(예: 5x5x3).

**연산 과정 (Convolving):**  
    필터를 입력 이미지의 좌측 상단부터 시작해 공간적으로 슬라이딩(Sliding)합니다.
    각 위치에서 필터와 이미지의 해당 영역 간의 **내적(Dot Product)**을 수행하고 편향(Bias)을 더합니다. 이는 $W^T x + b$와 같다.  
    **출력:**  
    필터 하나가 이미지를 훑고 지나가면 2차원의 **활성화 맵(Activation Map)** 이 생성된다.

**다중 필터:**  
    한 레이어에 여러 개의 필터(예: 6개)를 사용합니다. 각 필터는 서로 다른 특징을 학습합니다.
    각 필터가 만든 활성화 맵을 쌓으면 최종 출력은 28x28x6과 같은 **새로운 볼륨**이 된다.

**계층적 특징 학습:**  
    Conv 레이어 ReLU Pooling 등을 여러 번 쌓다.
    앞쪽 레이어는 엣지(Edge) 같은 단순한 특징을 중간은 코너나 얼룩 뒤쪽은 더 복잡한 객체 개념을 학습하게 된다. 이는 Hubel & Wiesel의 발견과 일치하는 현상이다.

### 6. 공간적 배치 (Spatial Arrangement) - 차원 계산
입력 크기 필터 크기 움직이는 간격 등에 따라 출력 크기가 어떻게 변하는지 상세히 다룹니다.

**예시 (7x7 입력 3x3 필터):**  
    **Stride 1:**  
    한 칸씩 움직이면 7x7 입력에서 5x5 출력이 나옵니다.  
    **Stride 2:**  
    두 칸씩 건너뛰며 움직이면 3x3 출력이 나옵니다.  
    **Stride 3:**  
    필터가 이미지 밖으로 삐져나가게 되어 딱 맞아떨어지지 않으므로 사용하지 않는다.

**출력 크기 공식:**  
$(N - F) / Stride + 1$

$N$: 입력 크기 $F$: 필터 크기.

**제로 패딩 (Zero Padding):**  
    가장자리에 0을 채워 넣는 기법이다.
1.  공식을 적용했을 때 크기가 줄어드는 것을 방지하여 **입력과 출력의 크기를 동일하게 유지**하기 위함이다. (예: 3x3 필터에 패딩 1을 주면 크기 유지).
2.  이미지의 가장자리나 코너 부분의 정보도 필터의 중심에서 처리될 수 있게 합니다.

**파라미터 수 계산 예제:**
    입력: 32x32x3 필터: 10개의 5x5 필터 Stride: 1 Pad: 2.  
    **출력 크기:**  
    $(32 + 2\times2 - 5) / 1 + 1 = 32$. 즉 32x32x10 볼륨이 나옵니다.  
    **파라미터 수:**  
    각 필터는 $5 \times 5 \times 3$ (가중치) $+ 1$ (편향) $= 76$개의 파라미터를 가집니다. 필터가 10개이므로 총 **760개**의 파라미터가 있다.

**1x1 Convolution:**  
공간적으로는 1x1이지만 깊이 전체를 관통하여 내적을 수행하므로 의미 있는 연산이며 자주 사용된다.

### 7. 뇌과학적 관점 (Brain View)
**지역적 연결성 (Local Connectivity):**  
뉴런이 입력의 전체가 아닌 특정 지역(수용 영역 Receptive Field)만 봅니다.

**파라미터 공유 (Parameter Sharing):**  
5x5 필터를 슬라이딩시킨다는 것은 해당 활성화 맵의 모든 뉴런들이 **동일한 가중치(파라미터)**를 공유한다는 뜻이다. 이미지의 어느 위치에서든 같은 특징(예: 가로 엣지)을 찾겠다는 의미이다.

### 8. 풀링 레이어 (Pooling Layer)
**목적:**  
표현(Representation)의 크기를 줄여서(Downsampling) 파라미터 수를 관리하고 연산량을 줄이며 약간의 불변성(Invariance)을 얻기 위함이다.

**특징:**  
깊이(Depth)에는 영향을 주지 않고 각 깊이 슬라이스(Slice)별로 독립적으로 공간적 크기만 줄이다.

**맥스 풀링 (Max Pooling):**  
    가장 일반적으로 사용된다. (예: 2x2 필터 Stride 2).
    겹치지 않게(Non-overlapping) 영역을 나누고 그 영역 안에서 **가장 큰 값**만 남깁니다.  
    "이 영역 어딘가에 이 특징이 존재하는가?"에 대해 가장 강한 신호만 남기는 것으로 해석할 수 있다.
참고로 최근에는 풀링 대신 Stride를 조절하여 다운샘플링하는 추세도 있다.

### 9. 전체 아키텍처 및 학습
**구조:**  
일반적으로 `[Conv - ReLU - Pool] x N -> FC -> Softmax` 형태를 띱니다.

**Fully Connected Layer (마지막 단계):**
    마지막 Conv/Pool 레이어의 출력(3D 볼륨)을 **모두 펼쳐서(Stretch)** 1차원 벡터로 만듭니다.
    이를 통해 공간적 정보를 모두 통합하여 최종적인 추론(분류 점수 계산)을 수행합니다.  
마지막 단계의 값들은 이미지가 가진 매우 복잡하고 고차원적인 특징들에 대한 정보를 담고 있다.

