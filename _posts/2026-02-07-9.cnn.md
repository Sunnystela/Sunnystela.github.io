---
layout: post
title: "[CS231n] 9. CNN Architectures"
date: 2026-02-07 09:50
categories: MyStudy CS231n
tags: cv CS231n
math: true
---

강의 주소: <br>
[CS231n Lecture 9. CNN Architectures](https://www.youtube.com/watch?v=6SlgtELqOWc&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=8)

자료: <br>
[깃허브 강의 자료](https://github.com/visionNoob/CS231N_17_KOR_SUB?tab=readme-ov-file)



### 1. 지난 시간 복습 
PyTorch, TensorFlow 같은 딥러닝 프레임워크를 다뤘다. 이러한 프레임워크는 계산 그래프를 쉽게 구축하고 모듈화된 레이어를 통해 복잡한 네트워크를 효율적으로 정의하며 GPU에서 빠르게 그래디언트를 계산할 수 있게 해준다.

### 2. CNN 아키텍처의 흐름
**AlexNet (2012) -> ZFNet (2013) -> VGGNet (2014) -> GoogLeNet (2014) -> ResNet (2015)**.

#### (1) LeNet-5 (1998)
가장 초기 형태의 성공적인 CNN으로 5x5 필터와 스트라이드 1을 사용했다. Conv 레이어와 Pooling 레이어를 거쳐 마지막에 Fully Connected 레이어로 숫자를 인식하는 구조다.

#### (2) AlexNet (2012)
**개요:**  
딥러닝 기반 모델로는 최초로 ImageNet 대회에서 우승하며 큰 격차로 성능을 입증했다. LeNet과 유사한 구조(Conv-Pool-Norm 반복 후 FC 레이어)를 갖지만 훨씬 더 깊고 크다.

**구조 및 크기 계산:**  
    **입력:**  
    227x227x3 이미지  
    **첫 번째 레이어 (Conv1):**  
    11x11 필터 96개를 stride 4로 적용한다.  
        출력 크기: $(227 - 11)/4 + 1 = 55$. **55x55x96** 볼륨이 된다.
        파라미터 수: $11 \times 11 \times 3 \text{ (입력 깊이)} \times 96 \text{ (필터 수)} \approx 35,000$개.  
    **두 번째 레이어 (Pool1):**  
    3x3 필터, stride 2를 사용한다.  
        출력 크기: $(55 - 3)/2 + 1 = 27$. 즉, **27x27x96**이 된다. 깊이(Depth)는 변하지 않는다.  
        파라미터 수: 풀링 레이어는 학습할 가중치가 없으므로 **0개**  

**세부 사항:**  
    **ReLU**를 처음 사용하여 비선형성을 확보했다.  
    **Local Response Normalization**을 사용했으나 이후 연구에서 효과가 미미하여 현재는 잘 쓰이지 않는다.  
    **데이터 증강(Data Augmentation):**   
    플립, 지터링, 크롭, 컬러 정규화 등을 많이 사용했다.  
    **Dropout (0.5), Batch size 128, SGD Momentum** 등을 사용했다.

**역사적 배경 (GPU 분할):**  
당시 GTX 580 GPU(3GB 메모리)로는 전체 모델을 담을 수 없어서 두 개의 GPU에 네트워크를 나누어 학습시켰다. 대부분의 레이어는 같은 GPU 내의 특징 맵(Feature map)만 보지만 특정 레이어(Conv3, FC6, FC7, FC8)에서만 GPU 간 통신이 이루어지는 구조였다.

#### (3) ZFNet (2013)
AlexNet의 하이퍼파라미터를 개선한 모델입니다. 구조는 동일하지만 스트라이드 크기나 필터 수 등을 조절하여 성능을 높였다.

#### (4) VGGNet (2014)
**핵심 아이디어:**  
네트워크를 훨씬 더 깊게 만들면서(16~19 레이어), 필터 크기를 **3x3**으로 아주 작게 유지했다.

**왜 작은 필터(3x3)인가?**  
    3x3 Conv 레이어를 3번 쌓으면(Stride 1), Effective Receptive Field은 **7x7**이 된다.
    이렇게 하면 7x7 필터 하나를 쓰는 것보다 파라미터 수는 줄이면서($3 \times (3^2C^2)$ vs $1 \times (7^2C^2)$), 비선형성(ReLU)은 더 많이 추가할 수 있어 더 훌륭한 특징을 학습할 수 있다.

**메모리 및 파라미터:**  
    이미지 한 장당 Forward pass에만 약 100MB의 메모리가 필요하다. 역전파까지 고려하면 더 많이 든다.  
    전체 파라미터 수는 **1억 3,800만 개**로 매우 많다. 대부분의 파라미터는 마지막 FC Layer들에 몰려 있다.

**성능:**  
ImageNet 2014에서 2위를 차지했다(우승은 GoogLeNet). FC7 레이어의 특징은 다른 작업으로 Transfer Learning할 때 매우 유용한 것으로 밝혀졌다.

#### (5) GoogLeNet (2014)
**핵심 아이디어:**  
22개 레이어로 깊지만, **계산 효율성**을 극대화하여 파라미터 수를 500만 개(AlexNet의 1/12)로 줄였다. FC 레이어를 없앤 것이 크다.

**인셉션 모듈 (Inception Module):**  
    동일한 입력에 대해 1x1, 3x3, 5x5 합성곱과 3x3 풀링을 병렬로 수행하고 결과를 Depth 방향으로 합친다(Concatenate).  
    **문제점:**  
    단순히 합치면 채널 수가 급격히 늘어나 연산량이 폭발한다.  
    **해결책 (Bottleneck Layer):**  
    비싼 연산(3x3, 5x5) 전에 **1x1 Conv**를 사용하여 채널 수를 먼저 줄인다. 이를 통해 연산량을 획기적으로 감소시킨다.  
    1x1 Conv는 정보 손실 우려가 있지만 채널 간의 선형 결합을 학습하고 비선형성을 추가하는 효과가 있어 실제로는 잘 작동한다.

**전체 구조:**  
'Stem' 네트워크로 시작해 인셉션 모듈을 쌓는다. 마지막에는 FC 레이어 대신 **Global Average Pooling**을 사용한다.

**보조 분류기 (Auxiliary Classifiers):**  
네트워크 중간중간에 추가적인 분류기(Loss)를 달아 깊은 네트워크에서도 그래디언트가 앞단까지 잘 전달되도록 도왔다.

### 3. ResNet (2015)
**혁명적인 깊이:**  
레이어 수가 152개로 급격히 증가했다.

**등장 배경:**  
일반적인 CNN(Plain net)은 레이어를 계속 쌓으면 성능이 오히려 떨어지는 현상이 발생했다. 이는 Overfitting 때문이 아니라 깊은 모델을 Optimization하기 어렵기 때문임이 밝혀졌다.

**Residual Learning:**  
    기존처럼 입력 $x$를 타겟 $H(x)$로 매핑하는 것을 바로 학습하는 대신 **$H(x) = F(x) + x$** 가 되도록 Residual인 $F(x)$를 학습한다.
     레이어는 입력에 대해 **변화량(Delta)** 만 학습하면 된다. 만약 아무것도 하지 않는 것이 최적이라면 가중치를 0으로 만들면 되므로 학습이 훨씬 쉽다.  
    **Skip Connection:**    
    입력을 출력에 더해주는 연결을 통해 그래디언트가 네트워크 전체로 잘 흐르게 한다.

**구조:**  
    모든 ResNet 블록은 3x3 Conv 두 개로 구성된다.
    50개 이상의 깊은 레이어 모델에서는 GoogLeNet처럼 **Bottleneck 구조**(1x1로 줄이고, 3x3 거치고, 1x1로 다시 늘림)를 사용하여 효율성을 높입니다.
    마지막에 FC 레이어 없이 Global Average Pooling을 사용한다.

**학습 방법:**  
모든 Conv 뒤에 Batch Norm을 사용하고 Xavier 초기화, SGD+Momentum 등을 사용했다. Dropout은 사용하지 않았다.

**결과:**  
ImageNet 2015의 모든 부문을 휩쓸었으며 인간의 성능보다 뛰어난 3.6% 에러율을 기록했다.

### 4. 모델 비교 및 기타 아키텍처
**복잡도 비교:**
    VGG: 메모리와 연산량이 가장 많아 비효율적이다.  
    GoogLeNet: 연산량이 가장 적고 효율적이다.  
    AlexNet: 정확도는 낮지만 연산량은 적다(메모리는 꽤 씀).  
    ResNet: 정확도가 가장 높으며 효율성은 중간 정도이다.

**기타 아키텍처 (ResNet 이후):**  
    **Network in Network (NiN):**  
    1x1 Conv(Bottleneck) 아이디어를 처음 제안했다.  
    **Identity Mappings in Deep ResNets:**  
    ResNet 블록 내부 구조를 개선하여 그래디언트 흐름을 더 좋게 만들었다.  
    **Wide ResNet:**  
    깊이보다는 너비(필터 수)를 늘리는 것이 효율적이며(병렬화 가능), 50층의 넓은 네트워크가 152층의 얇은 네트워크보다 좋을 수 있음을 보였다.  
    **ResNeXt:**  
    ResNet 블록 내에 여러 개의 병렬 경로(Cardinality)를 두어 성능을 개선했다.  
    **Stochastic Depth:**  
    학습 시 레이어를 무작위로 건너뛰어 얕은 네트워크처럼 학습하고, 테스트 때는 전체 깊이를 사용한다.  

**Non-ResNet 계열:**  
    **FractalNet:**  
    잔차 연결 없이 얕은 경로와 깊은 경로를 프랙탈 구조로 결합하여 깊은 네트워크를 학습한다.  
    **DenseNet:**  
    모든 레이어가 그 뒤의 모든 레이어와 연결되는 구조(Dense Block)를 가집니다. 특징을 재사용하고 그래디언트 소실을 막는다.  

**효율성 중심:**  
    **SqueezeNet:**  
    Fire module을 사용하여 AlexNet급 성능을 유지하면서 파라미터 수는 50배 줄였다.

