---
layout: post
title:  "idea" 
date:   2026-11-06 10:35
categories: mystudy 
tags: 
---


# ReLU
활성화함수가 비선형성을 추가하기 위함인데
렐루함수에서는 양수일때는 그대로 쓰는데 그게 어떻게 활성화함수로 역할을 하는지
> 선형적이라는 것이 잘 정의되어있지 않음. 그래서 0이하까지 같이봐서 그게 같이보면 비선형적으로 보이니 그렇다고 한다.

# 목적함수
(생각정리가 잘 안됨.)
목적함수 1/n하는데 저기 목적함수는 왜 1/c를 안하는지. 
그리고 1/2를 곱해도 왜 유효한지. 결과가 같은지


![alt](/assets/img/ida목적함수.png)





# cnn에서 Flatten 을 써야하나?

Flatten이 기본이라고는 하는데,
Flatten과 GAP(Global Average Pooling)의 구조적 차이, 파라미터 수, 과적합 측면에서 어떤 영향을 주는지 솔직히 정확히는 모르겠다.
왜 어떤 모델은 Flatten을 쓰고 어떤 모델은 GAP을 쓰는지 기준이 궁금함.

gap: 채널별로 평균값을 추출하여 피처맵을 생성하는 풀링
공간정보를 덜 잃는다고 하던데 평균으로 확 줄여버리는데 어떻게 공간 정보를 덜 잃는 것인지


# cnn dropout 0.4로 정했는데 적용 기준



# 8-2에 41페이지에 위치 정보를 담고 있다고 하셨는데
이게 특성맵이 담고있는 건지

특성맵이면 뒤가 flatten인데 의미있는 것인지
flatten이면 1차원으로 값이 나열된 것인데 어떻게 위치 정보가 있는 것인지


# 8-3에서 사진을 보면 엄청 비슷하게 생겼는데 어떻게 커널은 다르게 생겼는지 그 이유
두 모델 성능, 구성이 같더라도 채널은 완전 내용이 달라짐

llm 모델 병합
매칭 뭐랑 뭐랑 해야하는지
(?) 뭐라고 적었던 거지?


# C4W1 강의
소벨 샤를 필터에 대해

# C4W3 강의
Non-max Suppression의 클래스 간 간섭  
현재 알고리즘은 클래스별로 독립적으로 NMS를 실행합니다. 만약 서로 다른 클래스의 객체(예: 사람과 자전거)가 심하게 겹쳐 있는 상황에서 NMS가 한쪽 객체를 오인하여 제거하지 않도록 하려면 어떤 로직이 추가되어야 할까요?


# C4W4 강의


# VAE

노이즈 추가가 더 잘되는 이유
주변의 잠재 벡터로 생성하는데 멀어지면 더 다르다고 하는데
그냥 그 점으로 하는게 좋은거 아닌가

z공간을 몰라서 정규 분포라고 가정하는데
왜 하필 정규 분포로 가정하는지
몇 개의 단서로 조금이라도 유추할 수 없는지
왜 다른게 아닌지
-표준 정규 분포(Prior, $p(z)$)라는 '틀'은 과연 공정한가?모든 데이터를 평균 0, 분산 1인 공간에 구겨 넣는 것이 데이터 고유의 구조를 파괴하는 것은 아닌가? 만약 데이터가 본래 여러 개의 클러스터로 나뉘어 있다면, 단일 가우시안 Prior를 사용하는 것이 모델에게 '수학적 거짓말'을 강요하는 것은 아닌가?
-1. 가우시안 분포에 대한 집착: 왜 꼭 가우시안이어야 하는가?VAE는 잠재 변수 $z$가 표준 정규 분포를 따른다고 가정합니다. 하지만 데이터의 실제 매니폴드(Manifold)가 구멍이 뚫린 도넛 모양(Torus)이거나 여러 조각으로 나뉘어 있다면, 이를 억지로 하나의 덩어리인 가우시안으로 구겨 넣는 것이 과연 타당할까요?질문: 데이터의 기하학적 구조(Topology)와 Prior 분포 사이의 위상적 불일치가 발생할 때, VAE는 이를 어떻게 '왜곡'하여 학습하며, 이 왜곡이 생성된 데이터의 품질에 어떤 구체적인 악영향을 미치는가?

인코더와 디코더 중 누구의 책임이 더 큰가?VAE 학습이 잘 안 될 때, 그것은 인코더가 $z$를 의미 있게 추출하지 못해서인가, 아니면 디코더가 $z$를 해석하는 능력이 부족해서인가? ELBO의 두 항(Reconstruction vs KL)이 싸우는 과정에서 발생하는 '학습의 불균형'을 수치적으로 어떻게 진단할 수 있는가?
-4. Blur의 원인: MSE는 정말 범인인가?
VAE 결과물이 흐릿한 이유를 흔히 MSE(L2 Loss)의 평균 회귀 특성 때문이라고 합니다. 하지만 근본적으로는 확률 모델의 샘플링 과정에 원인이 있을 수 있습니다. 질문: VAE가 생성하는 '흐릿함'은 데이터의 불확실성(Aleatoric Uncertainty)을 모델이 확률적으로 표현하려고 노력한 결과물인가, 아니면 잠재 공간의 밀도가 너무 낮아 발생하는 보간(Interpolation) 오류인가?

이미지 흐릿하게 나옴
네트워크 아키텍처 때문이 ㅇ니라 손실함수의 정규화항 때문에 발생
-vae가 안좋으면 gan을 하면 되지 왜 계속 
-5. 2026년의 VAE: 왜 아직도 살아남았는가?
GAN이나 Diffusion 모델이 이미지 품질에서는 압도적이지만, 여전히 Stable Diffusion 같은 최신 모델들은 내부에 VAE를 핵심 부품으로 품고 있습니다. 질문: 생성 성능이 더 뛰어난 모델들이 많음에도 불구하고, VAE의 연속적인 잠재 공간 압축 능력을 대체할 수 있는 더 나은 수학적 대안이 아직 나오지 않은 근본적인 이유는 무엇인가? VAE는 생성 모델인가, 아니면 데이터의 '언어'를 만드는 번역기인가?
