---
layout: post
title: "[DeepLearning.AI] Course 5 of the Deep Learning Specialization"
date: 2026-01-25 12:50
categories: MyStudy DeepLearning.AI
tags: DeepLearning.AI DeepLearning
math: true
---

[Sequence Models (Course 5 of the Deep Learning Specialization)](https://www.youtube.com/watch?v=_i3aqgKVNQI&list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6)



## C5W3L01 Basic Models

### **1. 강의 도입 및 기계 번역 예시**
**Sequence Models**을 다룹니다.
시퀀스 모델은 기계 번역 음성 인식 등에 유용하게 사용됩니다.
프랑스어 문장(입력 $X$)을 영어 문장(출력 $Y$)으로 번역하는 과정을 예로 들어 입력 단어 수와 출력 단어 수가 다를 수 있음을 설명한다.

### **2. Encoder-Decoder 아키텍처**
**인코더 네트워크:**  
GRU나 LSTM과 같은 RNN을 사용하여 입력 문장의 단어들을 하나씩 처리하고 전체 문장을 나타내는 **vector**를 출력한다.

**디코더 네트워크:**  
인코더가 생성한 벡터를 입력으로 받아 **문장의 끝** 토큰이 나올 때까지 번역된 단어를 하나씩 생성한다.
이 모델은 충분한 데이터(프랑스어-영어 쌍)가 있다면 놀라울 정도로 잘 작동한다.

### **3. Image Captioning으로의 확장**
이미지를 입력하면 그 내용을 설명하는 문장을 출력하는 **이미지 캡셔닝**에도 유사한 구조가 적용됩니다.

**인코더:**  
사전 학습된 **AlexNet**과 같은 컨벌루션 신경망(CNN)에서 마지막 소프트맥스 층을 제거하고 이미지를 나타내는 **feature vector**(예: 4096차원)를 추출하여 인코더 역할을 수행한다.

**디코더:**  
추출된 특징 벡터를 RNN의 입력으로 사용하여 캡션 문장을 단어 단위로 생성한다.

### **4. 언어 모델과의 차이점 및 향후 과제**
일반적인 텍스트 생성 언어 모델과 기계 번역/이미지 캡셔닝 모델의 핵심적인 차이점은 **출력의 선택 방식**이다.

단순히 무작위로 문장을 생성하는 것이 아니라 **가장 가능성이 높은(most likely)** 번역이나 캡션을 찾아내야 한다.
다음 강의에서는 이를 위해 최적의 결과물을 찾아내는 방법에 대해 다룰 예정이다.


## C5W3L02 Picking the most likely sentence

### **1. 기계 번역과 조건부 언어 모델 (Conditional Language Model)**
기계 번역 모델은 기존의 언어 모델과 유사하지만 중요한 차이점이 있다. 언어 모델이 단순히 문장의 확률을 추정하고 새로운 문장을 생성한다면 기계 번역은 **입력 문장이 주어졌을 때 번역문의 확률을 추정하는 '조건부 언어 모델'**이다.
기계 번역 모델은 입력 문장을 표현(representation)으로 바꾸는 **인코딩 네트워크(그린)**와 이를 바탕으로 번역을 생성하는 **디코딩 네트워크(퍼플)**로 구성됩니다. 디코딩 네트워크는 0으로 시작하는 일반 언어 모델과 달리 인코딩된 입력 문장의 정보를 바탕으로 시작됩니다.

### **2. 확률 최대화 (Maximizing Probability)**
기계 번역의 목표는 입력 프랑스어 문장($x$)이 주어졌을 때 **조건부 확률 $P(y|x)$를 최대화하는 영어 번역문($y$)을 찾는 것**이다.
이 과정에서 무작위로 단어를 샘플링하는 방식은 적절하지 않다. 자칫 어색하거나 질이 낮은 번역문이 선택될 수 있기 때문이다. 따라서 **전체 문장의 확률을 극대화하는 알고리즘**이 필요한다.

### **3. 탐욕 알고리즘(Greedy Search)의 한계**
**탐욕 알고리즘**은 첫 번째 단어부터 시작해 매 단계에서 가장 확률이 높은 단어를 하나씩 선택해 나가는 방식이다. 
하지만 이 방식은 **문장 전체의 최적 확률을 보장하지 못한다**. 예를 들어 문장 초반에 더 흔한 단어(예: "going")를 선택했다가 결과적으로는 덜 자연스러운 긴 문장이 만들어질 수 있고 오히려 초반에 조금 덜 흔한 단어(예: "visiting")를 선택했을 때 더 간결하고 정확한 전체 문장이 나올 수도 있기 때문이다.

### **4. 탐색 공간의 크기와 근사 알고리즘의 필요성**
언어의 조합은 기하급수적으로 많다. 예를 들어 단어장이 10000개이고 10단어로 된 문장을 만든다면 가능한 조합은 $10000^{10}$개에 달해 모든 경우를 일일이 확인하는 것은 불가능한다.
따라서 현실적으로는 모든 문장을 전수 조사하는 대신 **빔 서치(Beam Search)**와 같은 **근사 탐색 알고리즘(Approximate Search Algorithm)**을 사용한다. 이 알고리즘은 항상 완벽한 최댓값을 찾는다고 보장할 수는 없지만 대개 **조건부 확률을 충분히 높여주는 최선의 번역문**을 효율적으로 찾아내는 역할을 한다.


## C5W3L06 Bleu Score (Optional)

### **1. 기계 번역 평가의 문제점 제시**
기계 번역의 어려운 점 중 하나는 하나의 프랑스어 문장에 대해 **동등하게 훌륭한 여러 개의 영어 번역문이 존재할 수 있다**는 점이다.
이미지 인식처럼 정답이 하나인 경우와 달리 여러 개의 좋은 답안이 있을 때 시스템의 정확도를 어떻게 측정할 것인가가 핵심 과제이다.

이러한 문제를 해결하기 위해 **BLEU(Bilingual Evaluation Understudy) 스코어**가 고안되었다.

### **2. BLEU 스코어의 개념과 직관**
BLEU는 사람이 직접 기계 번역 결과를 평가하는 것을 대신하여 기계가 생성한 번역이 사람이 만든 Reference 문장들과 얼마나 유사한지를 **자동으로 수치화**한다.

기본적인 아이디어는 기계가 생성한 단어들이 사람이 작성한 참조 문장 중 적어도 하나에 나타나는지 확인하는 것이다.

### **3. Modified Precision 도입**
단순히 단어가 포함되었는지 여부만 따지는 '정밀도'는 "the the the..."와 같은 잘못된 번역에도 높은 점수를 주는 허점이 있다.

이를 해결하기 위해 **Modified Precision**를 사용한다. 이는 각 단어에 대해 **참조 문장에 나타난 최대 횟수만큼만 점수를 부여(Clip)** 하는 방식이다.

### **4. Unigram에서 n-gram으로의 확장** 
개별 단어(유니그램)뿐만 아니라 **인접한 단어 쌍(n-그램)** 의 일치 여부도 함께 측정한다.

**Bigram** 예시를 통해 기계가 생성한 단어 쌍이 참조 문장에 나타나는 횟수를 계산하고 이를 'Clipped'하여 정밀도를 구하는 과정을 설명한다.

동일한 방식으로 유니그램($P_1$) 바이그램($P_2$) 트라이그램($P_3$) 4-그램($P_4$) 등에 대한 정밀도를 각각 계산할 수 있다.

### **5. 최종 BLEU 스코어 계산과 짧은 문장 패널티(BP)**
최종 BLEU 스코어는 $P_1$부터 $P_4$까지의 값을 결합하여 하나의 숫자로 산출한다.
이때 **짧은 문장에 대한 패널티(Brevity Penalty BP)** 가 적용됩니다. 이는 단순히 짧은 문장을 출력하여 정밀도를 높이려는 시스템을 방지하기 위함이며 참조 문장보다 짧은 경우 점수를 깎는다.

### **6. BLEU 스코어의 의의와 활용**
BLEU 스코어는 기계 번역 분야에서 **Single real number evaluation metric**를 제공함으로써 연구 속도를 획기적으로 가속화했다.

이 지표는 기계 번역뿐만 아니라 **Image Captioning** 등 텍스트를 생성하고 사람이 만든 기준과 비교해야 하는 다양한 분야에 사용된다.

다만 정답이 명확한 Speech Recognition에는 일반적으로 사용되지 않다.


## C5W3L07 Attention Model Intuition

### **1. 기존 인코더-디코더 모델의 한계**
**기존 방식:**  
인코더 RNN이 전체 프랑스어 문장을 읽어 메모리에 저장한 후 디코더 RNN이 영어 문장을 생성하는 구조이다.
**문제점:**  
인간 번역가는 긴 문장을 한 번에 다 외워서 번역하지 않고 부분별로 나누어 작업한다. **기존 모델은 짧은 문장에는 효과적이지만 30~40단어가 넘어가는 긴 문장에서는 전체를 암기하는 데 한계가 있어 성능(Blue score)이 급격히 저하됩니다**.

### **2. 어텐션(Attention) 모델의 도입**
**핵심 아이디어:**  
인간처럼 **문장의 특정 부분에 집중(Attention)**하여 번역을 수행한다. 이를 통해 긴 문장에서도 성능이 떨어지지 않고 유지됩니다.
**의의:**  
Bahdanau 등이 개발한 이 모델은 기계 번역뿐만 아니라 다양한 딥러닝 분야에 응용된 매우 영향력 있는 모델이다.

### **3. 모델 구조와 작동 원리 (Intuition)**
**양방향 RNN (Bi-directional RNN):**  
입력 문장의 각 단어(또는 위치)에 대해 앞뒤 문맥을 모두 고려한 **풍부한 특징(Features) 세트**를 계산한다.
**어텐션 가중치 ($\alpha$):**  
영어 단어를 하나씩 생성할 때마다 프랑스어 입력 문장의 각 부분에 **얼마나 많은 주의(Attention)를 기울여야 하는지**를 나타내는 가중치이다.
    예를 들어 첫 단어 'Jane'을 생성할 때는 입력 문장의 첫 부분에 높은 가중치($\alpha_{11}$)를 둡니다.
**컨텍스트 벡터 ($c$):**  
선택된 어텐션 가중치와 양방향 RNN의 활성화 값을 결합하여 생성된 맥락 정보로 디코더 RNN의 입력으로 사용됩니다.
**디코더의 상태 변수 ($s$):**  
기존 활성화 값인 $a$와 구분하기 위해 디코더의 은닉 상태는 $s$로 표기하며 **이전 단계의 상태($s_{t-1}$)와 양방향 RNN의 활성화 값이 현재 단계의 어텐션 가중치를 결정**하는 데 영향을 줍니다.

### **4. 요약 및 결론**
디코더는 문장의 끝(EOS) 토큰이 나올 때까지 **한 번에 한 단어씩 행진하듯 생성**한다.
이 과정에서 매번 **로컬 윈도우(특정 범위)의 입력 문장을 참조**함으로써 신경망이 아주 긴 문장을 통째로 암기해야 하는 부담을 덜어줍니다.
다음 강의에서는 이러한 어텐션 가중치와 컨텍스트 벡터를 계산하는 구체적인 알고리즘 세부 사항을 다룰 예정이다.


## C5W3L08 Attention Model


### **1. 입력 문장 인코딩: 양방향 RNN의 활용**
어텐션 모델을 구현하기 위해 먼저 **양방향 RNN(Bi-directional RNN)**(또는 GRU LSTM)을 사용하여 입력 문장의 각 단어에 대한 특징 벡터를 계산한다.
각 타임스텝 $t'$에서의 특징 벡터 $a^{\langle t' \rangle}$는 순방향(forward) 활성화 값과 역방향(backward) 활성화 값을 **연결(concatenation)**하여 표현한다.

### **2. 컨텍스트 벡터(Context Vector)와 어텐션 가중치**
번역문을 생성하는 디코더는 단방향 RNN을 사용하며 각 단계에서 **컨텍스트 벡터($c$)**를 입력으로 받다.
컨텍스트 벡터는 입력 문장의 특징 벡터($a^{\langle t' \rangle}$)들을 **가중 합산(weighted sum)**한 값이다.
이때 사용되는 가중치인 **어텐션 가중치($\alpha^{\langle t t' \rangle}$)**는 출력 단어 $y^{\langle t \rangle}$를 생성할 때 입력 단어 $t'$에 얼마나 많은 주의를 기울여야 하는지를 나타냅니다.

### **3. 어텐션 가중치의 계산 방법**
어텐션 가중치 $\alpha^{\langle t t' \rangle}$를 구하기 위해 먼저 $e^{\langle t t' \rangle}$라는 값을 계산한 후 **소프트맥스(Softmax)** 함수를 적용하여 모든 가중치의 합이 1이 되도록 만듭니다.
$e^{\langle t t' \rangle}$는 **작은 신경망**을 통해 계산되는데 이 네트워크의 입력은 디코더의 **이전 은닉 상태($s^{\langle t-1 \rangle}$)**와 입력 문장의 **특징 벡터($a^{\langle t' \rangle}$)**이다.
이 함수가 정확히 무엇인지 미리 정의하는 대신 **경사 하강법(Gradient Descent)**과 역전파를 통해 모델이 스스로 학습하도록 한다.

### **4. 모델의 장점과 비용적 한계**
이 모델은 출력 단어를 생성할 때 입력 문장의 적절한 부분에 자동으로 집중하며 매우 효과적으로 작동한다.
단점으로는 **이차 비용(Quadratic Cost)**이 발생한다는 점이다. 입력 단어 수가 $T_x$이고 출력 단어 수가 $T_y$일 때 어텐션 매개변수의 총 개수는 $T_x \times T_y$가 됩니다. 다만 일반적인 기계 번역 문장 길이는 아주 길지 않으므로 대개의 경우 감당할 수 있는 수준이다.

### **5. 다양한 응용 분야 및 시각화**
**응용:**  
이 모델은 기계 번역뿐만 아니라 이미지의 특정 부분에 집중하여 설명을 적는 **이미지 캡셔닝(Image Captioning)**이나 다양한 형식의 날짜를 표준 형식으로 변환하는 **날짜 정규화(Date Normalization)** 문제에도 적용될 수 있다.
**시각화:**  
어텐션 가중치를 시각화해 보면 특정 단어를 출력할 때 그와 연관된 입력 단어의 가중치가 높게 나타나는 것을 확인할 수 있으며 이는 모델이 올바른 곳에 집중하는 법을 스스로 학습했음을 보여줍니다.


## C5W3L09 SpeechRecog

### **1. 음성 인식 문제의 정의**
음성 인식은 **오디오 클립($X$)을 입력받아 텍스트 스크립트($Y$)를 자동으로 찾아내는 과정**이다.
오디오 데이터는 기본적으로 시간에 따른 공기압의 미세한 변화를 측정한 것인데 알고리즘은 이를 처리하여 문장으로 출력한다.

### **2. 오디오 데이터의 전처리: 스펙트로그램(Spectrogram)**
인간의 귀처럼 원시 파형(raw waveforms)을 직접 처리하는 대신 전처리 단계로 **스펙트로그램**을 생성한다.
스펙트로그램은 가로축은 시간 세로축은 주파수를 나타내며 색의 강도로 특정 시간대와 주파수에서의 에너지 양(소리 크기)을 보여줍니다.

### **3. 음성 인식 기술의 변화: 음소(Phonemes)에서 End-to-End로**
과거에는 언어학자들이 정의한 최소 소리 단위인 **음소(Phonemes)**를 사용하여 시스템을 구축했다.

그러나 **End-to-end deep learning**의 발전으로 이제는 음소 표현 없이 오디오 클립에서 바로 텍스트를 출력할 수 있게 되었다.

이러한 변화는 수천에서 수십만 시간에 달하는 **대규모 데이터셋**이 확보되면서 가능해졌다.

### **4. 딥러닝 모델 아키텍처**
음성 인식을 위해 **Attention model**을 사용하거나 **CTC(Connectionist Temporal Classification) 비용 함수**를 활용할 수 있다.

실제 구현 시에는 단방향 RNN보다는 주로 **양방향 LSTM(Bidirectional LSTM)이나 GRU**와 같은 깊은 모델을 사용한다.

### **5. CTC(Connectionist Temporal Classification)의 원리**
음성 인식에서는 입력 타임 스텝(예: 1000개)이 출력 캐릭터 수(예: 19개)보다 훨씬 많은 것이 일반적이다.

**CTC 비용 함수**는 이를 해결하기 위해 **특수 문자 'blank(빈칸)'**와 **반복된 문자를 하나로 합치는 규칙**을 사용한다.
>"TTT_h_eee"라는 출력이 있다면 blank(_)가 없는 구간의 반복된 글자를 합쳐 "The"로 변환한다.

이 방식을 통해 수천 개의 출력 값을 가지는 신경망이 훨씬 짧은 텍스트 스크립트를 효과적으로 표현할 수 있다.

현재 프로덕션 수준의 음성 인식 시스템을 구축하는 것은 매우 방대한 데이터가 필요한 큰 작업이다.


