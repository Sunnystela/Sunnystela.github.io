---
layout: post
title: "[CS231n] 2. Image Classification"
date: 2026-01-11 09:50
categories: MyStudy CS231n
tags: cv CS231n
math: true
---

강의 주소: <br>
[CS231n 유튜브 링크](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk)

자료: <br>
[깃허브 강의 자료](https://github.com/visionNoob/CS231N_17_KOR_SUB?tab=readme-ov-file)


### 1. 강의 소개 

**Python/Numpy 중요성:**  
모든 과제는 Python과 Numpy를 사용하며 특히 벡터화 연산(vectorized operations)을 통해 효율적인 코드를 작성하는 것이 머신러닝에서 매우 중요합니다.

### 2. 이미지 분류(Image Classification)의 개요
**정의:**  
컴퓨터가 입력 이미지를 받아 미리 정해진 카테고리(라벨) 집합 중 하나를 할당하는 작업입니다.

**의미적 차이(Semantic Gap):**  
사람은 이미지를 볼 때 고양이와 같은 개념(Semantic)을 직관적으로 인식하지만 컴퓨터에게 이미지는 0~255 사이의 거대한 숫자 그리드(픽셀 값)일 뿐입니다. 이 차이를 'Semantic Gap'이라고 합니다.

**주요 난관:**  
알고리즘은 다음과 같은 변화에도 강건(robust)해야 합니다.  
    **시점 변화(Viewpoint variation):**  
    카메라 각도가 바뀌면 픽셀 값은 완전히 달라집니다.  
    **조명(Illumination) 변형(Deformation) 가려짐(Occlusion):**  
    고양이가 몸을 비틀거나 소파 뒤에 숨어 있어도 인식해야 합니다.  
    **배경 혼동(Background Clutter) 및 클래스 내 변이(Intraclass variation):**  
    배경과 객체가 비슷하거나 같은 고양이 종이라도 생김새가 다양할 수 있습니다.

### 3. 데이터 기반 접근법(Data-Driven Approach)
**기존 방식의 한계:**  
"귀가 있고 눈이 있으면 고양이"라는 식의 규칙을 하드코딩하는 방식은 부서지기 쉽고(brittle) 확장성이 없습니다.

**새로운 접근:**  
데이터를 이용하는 방식입니다.
1.  이미지와 라벨이 포함된 대규모 데이터셋을 수집합니다.
2.  머신러닝 분류기를 사용해 데이터를 학습(Train)하고 모델을 만듭니다.
3.  새로운 이미지에 대해 모델을 사용해 예측(Predict)합니다.

### 4. Nearest Neighbor (최근접 이웃) 분류기
**알고리즘:**  
가장 단순한 형태의 분류기입니다.  
    **Train:**  
    모든 학습 데이터를 기억(메모리 저장)합니다.  
    **Predict:**  
    새로운 이미지와 가장 유사한 학습 이미지를 찾아 그 라벨을 예측값으로 내놓습니다.

**거리 척도(Distance Metric):**  
이미지 간의 유사도를 측정하기 위해 L1 거리(Manhattan distance 픽셀 간 차이의 절댓값 합) 등을 사용합니다.

**속도 문제:**  
학습은 단순히 데이터를 저장하므로 빠르지만(O(1)) 예측할 때는 모든 학습 데이터와 비교해야 하므로 매우 느립니다(O(N)). 이는 실제 배포 환경(빠른 예측 필요)과는 정반대되는 특성입니다.

### 5. K-Nearest Neighbors (KNN)
**개념:**  
가장 가까운 이웃 하나만 보는 대신 가장 가까운 **K개**의 이웃을 찾고 다수결(majority vote)로 라벨을 결정합니다. 이는 결정 경계(decision boundary)를 부드럽게 만들고 노이즈에 더 강건하게 만듭니다.

**거리 척도 비교:**  
    **L1 거리:**  
    좌표계에 의존적입니다. 데이터 벡터의 각 요소가 개별적인 의미를 가질 때 유용할 수 있습니다.  
    **L2 거리(Euclidean):**  
    좌표축 회전에 영향을 받지 않습니다. 일반적인 기하학적 거리를 의미합니다.

### 6. 하이퍼파라미터(Hyperparameters) 설정
**정의:**  
K값이나 거리 척도(L1 vs L2)처럼 학습되는 것이 아니라 사전에 설정해야 하는 값들을 말합니다.

**올바른 설정 방법:**  
    **절대 하지 말 것:**  
    학습 데이터셋(Training set)이나 테스트 데이터셋(Test set)에 맞춰 하이퍼파라미터를 조정하면 안 됩니다. 이는 과적합(Overfitting)을 유발하며 본 적 없는 데이터에 대한 성능을 보장하지 못합니다.  
    **권장 방법:**  
    데이터를 **Train(학습) Validation(검증) Test(테스트)** 세 부분으로 나눕니다. 학습 세트로 모델을 훈련하고 검증 세트로 하이퍼파라미터를 튜닝한 뒤 마지막에 딱 한 번 테스트 세트로 최종 성능을 평가합니다.  
    **교차 검증(Cross Validation):**  
    데이터가 적을 때 유용하며 데이터를 여러 폴드(fold)로 나누어 번갈아 가며 검증합니다. 하지만 딥러닝에서는 계산 비용 문제로 잘 쓰이지 않습니다.

### 7. 이미지 분류에서 KNN의 한계
**느린 예측 속도:**  
테스트 시간이 너무 오래 걸립니다.

**부적절한 거리 척도:**  
L2 거리 등은 픽셀 간 차이만 계산하므로 사람이 인지하는 이미지의 유사도(perceptual similarity)를 잘 반영하지 못합니다. 예를 들어 이미지를 살짝 이동하거나 색조를 바꿔도 L2 거리는 동일할 수 있습니다.

**차원의 저주(Curse of Dimensionality):**  
공간을 조밀하게 덮으려면 차원이 늘어날수록 기하급수적으로 많은 데이터가 필요합니다. 고해상도 이미지는 차원이 매우 높으므로 KNN을 제대로 적용하기 어렵습니다.

### 8. 선형 분류기(Linear Classification)
**의미:**  
신경망(Neural Networks)을 레고 블록에 비유한다면 선형 분류기는 가장 기본적인 구성 요소입니다.

**파라메트릭 접근(Parametric Approach):**  
학습 데이터를 모두 저장하는 대신 데이터를 요약하는 파라미터 $W$(가중치)를 학습합니다. 예측 함수는 $f(x W) = Wx + b$ 형태를 가집니다.
    입력 이미지 $x$를 긴 벡터로 펼치고 가중치 행렬 $W$와 곱한 뒤 편향 $b$를 더해 각 클래스에 대한 점수(score)를 계산합니다.

**해석:** 
1.  **템플릿 매칭(Template Matching):**  
    가중치 행렬 $W$의 각 행은 특정 클래스에 대한 '템플릿' 역할을 합니다. 내적(dot product)을 통해 이미지와 템플릿의 유사도를 측정합니다. 시각화해보면 모든 학습 데이터를 평균 낸 것처럼 모호한 형태(예: 머리가 두 개 달린 말)가 나타납니다. 이는 클래스당 하나의 템플릿만 학습할 수 있는 선형 분류기의 한계입니다.
2.  **기하학적 해석:**  
    고차원 공간에서 각 클래스를 구분하는 선형 경계(평면)를 긋는 것으로 이해할 수 있습니다.

**한계:**  
데이터가 선형적으로 분리되지 않는 경우(예: XOR 문제와 같은 Parity 문제 데이터가 여러 섬처럼 떨어져 있는 Multimodal 경우)에는 선형 분류기로 해결할 수 없습니다.

**결론:**  
이번 강의에서는 이미지 분류의 기본 개념과 KNN 선형 분류기의 구조를 배웠습니다. 다음 강의에서는 이 선형 분류기의 파라미터 $W$를 실제로 어떻게 찾을 것인지(손실 함수와 최적화)에 대해 다루게 됩니다.



선형 분류기의 '템플릿 매칭' 방식은 마치 **"여러 장의 사진을 겹쳐서 평균을 낸 흐릿한 유령 사진"**과 비교할 수 있습니다. 예를 들어 왼쪽을 보는 말 사진과 오른쪽을 보는 말 사진을 모두 학습하면 선형 분류기는 이 둘을 모두 만족시키려다 결국 '머리가 양쪽으로 달린 이상한 말' 템플릿을 기억하게 됩니다. 이것이 바로 단순 선형 모델이 복잡한 시각적 변이를 완벽하게 처리하지 못하는 이유입니다.